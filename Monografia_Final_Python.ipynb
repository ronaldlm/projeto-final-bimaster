{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Monografia_(57).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdumIygB0GIx"
      },
      "source": [
        "# **Projeto Final do Curso de pós-graduação BI-Master da PUC-RIO**\n",
        "\n",
        "Aluno: Ronald Alzamende Martins\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVr6nh3Ga5r1"
      },
      "source": [
        "# Montagem do drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWcvqxl7a4zG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJIcfimAb9Os"
      },
      "source": [
        "# Direcionando para uma pasta dentro do drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30SnTWVxcKek"
      },
      "source": [
        "if (True):\n",
        "  import os\n",
        "  os.chdir(\"drive/MyDrive/TCC\")  #MAPEAR PARA O LOCAL NO DRIVE ONDE os arquivos serão armazenados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpPn9QF9ot5H"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UzGYtHd53n5"
      },
      "source": [
        "# **PRIMEIRA ETAPA - Coleta de dados**\n",
        "\n",
        "Os dados utilizados neste trabalho são dados públicos, publicados semanalmente pelo Instituto Nacional da Propriedade Industrial (INPI) através da RPI - Revista da Propriedade Industrial, no website da instituição:\n",
        "http://revistas.inpi.gov.br/rpi/. \n",
        "\n",
        "Atualmente, a RPI é publicada todas as terças-feiras. Em cada RPI há despachos relativos somente aos pedidos de patente de invenção ou de modelo de utilidade. Estes despachos serão explicados com mais detalhes na próxima etapa.\n",
        "\n",
        "O nosso objetivo, neste trabalho, será o de formar dataframes a partir da extração das informações contidas nos despachos das RPI's, e então poder fazer algumas análises dos dados extraídos.\n",
        "\n",
        "Antecipadamente, sabemos que, no período que serão extraídas as rpi's, o número total de rpi's é de 1453, isto é, no final da coleta, teremos que ter 1453 arquivos .txt!\n",
        "\n",
        "O download de cada RPI do site será feito utilizando-se as bibliotecas Selenium e BeautifulSoup \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl79SHwAczCW"
      },
      "source": [
        "Instalando as bibliotecas necessárias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "illj9LtL_im8"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSOc1hPuhQ-m"
      },
      "source": [
        "!wget https://chromedriver.storage.googleapis.com/2.42/chromedriver_linux64.zip  && unzip chromedriver_linux64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFje_cAC_iwK"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_argument('--start-maximized')\n",
        "chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36')\n",
        "chrome_options.add_argument('--ignore-certificate-errors')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options, service_args=['--verbose', '--log-path=/tmp/chromedriver.log'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15vV15SNd-z8"
      },
      "source": [
        "# Importando a biblioteca beautifulsoup\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import subprocess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn7Ywn_E_i2S"
      },
      "source": [
        "# Acessando a URL\n",
        "wd.get(\"http://revistas.inpi.gov.br/rpi/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c7M_b8ydy_f"
      },
      "source": [
        "Uma das vantagens de se utilizar a biblioteca selenium é a facilidade em simular as ações de um usuário ao acessar determinada url, sendo uma delas a de dar um click em determinado local e digitar uma informação necessária."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3THTyDXTKmj"
      },
      "source": [
        "Vamos verificar o código, passo a passo, vamos usar o período 01/01/1993 a 10/01/1993 para testar se o código está funcionando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7lvbF2_OoVA"
      },
      "source": [
        "# 1º ação do usuário na página, clicar no campo \"Buscar Patentes\"\n",
        "busca_patente = wd.find_element_by_xpath('//a[@id=\"6\"]')\n",
        "busca_patente.click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpKYgF4aOoX8"
      },
      "source": [
        "# 2º ação do usuário na página, clicar no tipo de pesquisa \"por data\"\n",
        "tipo_pesquisa = wd.find_element_by_xpath('//input[@value=\"2\"]')\n",
        "tipo_pesquisa.click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCc9z-EKOoad"
      },
      "source": [
        "# 3º ação do usuário na página, entrar com a data inicial de publicação da rpi\n",
        "data_inicial = wd.find_element_by_xpath('//input[@id=\"dataInicial\"]')\n",
        "data_inicial.click()\n",
        "print(\"Digite a data inicial no formato xx/xx/xxxx e tecle enter\")\n",
        "inicial=input() # utilizando o método input para entrar com a data inicial\n",
        "data_inicial.send_keys(inicial)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BJYrIh8OodP"
      },
      "source": [
        "# 4º ação do usuário na página, entrar com a data final de publicação da rpi\n",
        "data_final = wd.find_element_by_xpath('//input[@id=\"dataFinal\"]')\n",
        "data_final.click()\n",
        "print(\"Digite a data final no formato xx/xx/xxxx, e tecle enter\")\n",
        "final=input() # utilizando o método input para entrar com a data final\n",
        "data_final.send_keys(final)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUTTgll_Oofq"
      },
      "source": [
        "# 5º ação do usuário, clicar no botão Buscar\n",
        "button = wd.find_elements_by_xpath('//button[@class=\"btn rst\"]')[1]\n",
        "button.click()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEgzzKzjOoiM"
      },
      "source": [
        "# E, finalmente, extraindo o conteúdo da busca que aparece no site da rpi\n",
        "result = wd.find_element_by_xpath('//tbody[@id=\"resultado\"]')\n",
        "result_rpi=result.get_attribute('innerHTML')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjCWAVGqOooy"
      },
      "source": [
        "# Visualizando o que é extraído da página:\n",
        "result_rpi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8efDdpFcQio"
      },
      "source": [
        "# Utilizando o beautifulsoup para traduzir a linguagem html\n",
        "rpi_page_soup = BeautifulSoup(result_rpi,'html.parser')\n",
        "rpi_page_soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2jRwUcVNlyY"
      },
      "source": [
        "# Pegando todos os arquivos \n",
        "page_links_url = [a['href'] for a in rpi_page_soup.find_all('a', href=True)]\n",
        "page_links_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22S-DdG1TjKa"
      },
      "source": [
        "# Pegando os arquivos somente com extensão .zip\n",
        "page_zip_urls = [zip_url for zip_url in page_links_url if \".zip\" in zip_url]\n",
        "page_zip_urls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeJie309ZeLx"
      },
      "source": [
        "# Verificando o tamanho da lista\n",
        "len(page_zip_urls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1krz4-4YZp3f"
      },
      "source": [
        "Agora vamos fazer o download das revistas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnqTg17OXcwC"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "for url in page_zip_urls:\n",
        "  print(\"Extraindo o pdf da url: \", url)\n",
        "  getRpm = 'wget --no-check-certificate -P ./ %s' %url\n",
        "  subprocess.run(getRpm, shell=True)\n",
        "\n",
        "print(\"Processo finalizado!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_YPR5O69rJa"
      },
      "source": [
        "O código funcionou, passo a passo,  para extrair as revistas no período de 01/01/1993 a 10/01/1993. Vamos juntar as etapas, excluir a revista já extraída e extrair as RPI's no período de 01/01/1993 a 08/12/2020."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LhMUW8V9qUu"
      },
      "source": [
        "# Para cada ação, vamos inserir um tempo de espera (time.sleep()) no código para a ação poder ser realizada:\n",
        "import time\n",
        "\n",
        "# Acessando a URL\n",
        "wd.get(\"http://revistas.inpi.gov.br/rpi/\")\n",
        "time.sleep(2)\n",
        "\n",
        "# 1º ação do usuário na página, clicar no campo \"Buscar Patentes\"\n",
        "busca_patente = wd.find_element_by_xpath('//a[@id=\"6\"]')\n",
        "busca_patente.click()\n",
        "time.sleep(2)\n",
        "\n",
        "# 2º ação do usuário na página, clicar no tipo de pesquisa \"por data\"\n",
        "tipo_pesquisa = wd.find_element_by_xpath('//input[@value=\"2\"]')\n",
        "tipo_pesquisa.click()\n",
        "time.sleep(2)\n",
        "\n",
        "# 3º ação do usuário na página, entrar com a data inicial de publicação da rpi\n",
        "data_inicial = wd.find_element_by_xpath('//input[@id=\"dataInicial\"]')\n",
        "data_inicial.click()\n",
        "print(\"Digite a data inicial no formato xx/xx/xxxx e tecle enter\")\n",
        "inicial=input() # utilizando o método input para entrar com a data inicial\n",
        "data_inicial.send_keys(inicial)\n",
        "time.sleep(2)\n",
        "\n",
        "# 4º ação do usuário na página, entrar com a data final de publicação da rpi\n",
        "data_final = wd.find_element_by_xpath('//input[@id=\"dataFinal\"]')\n",
        "data_final.click()\n",
        "print(\"Digite a data final no formato xx/xx/xxxx, e tecle enter\")\n",
        "final=input() # utilizando o método input para entrar com a data final\n",
        "data_final.send_keys(final)\n",
        "time.sleep(2)\n",
        "\n",
        "# 5º ação do usuário, clicar no botão Buscar\n",
        "button = wd.find_elements_by_xpath('//button[@class=\"btn rst\"]')[1]\n",
        "button.click()\n",
        "time.sleep(4)\n",
        "\n",
        "# E, finalmente, extraindo o conteúdo da busca que aparece no site da rpi\n",
        "result = wd.find_element_by_xpath('//tbody[@id=\"resultado\"]')\n",
        "result_rpi=result.get_attribute('innerHTML')\n",
        "time.sleep(3)\n",
        "\n",
        "# Utilizando o beautifulsoup para traduzir a linguagem html\n",
        "rpi_page_soup = BeautifulSoup(result_rpi,'html.parser')\n",
        "time.sleep(3)\n",
        "\n",
        "# Pegando todos os arquivos \n",
        "page_links_url = [a['href'] for a in rpi_page_soup.find_all('a', href=True)]\n",
        "time.sleep(3)\n",
        "\n",
        "# Pegando os arquivos somente com extensão .zip\n",
        "page_zip_urls = [zip_url for zip_url in page_links_url if \".zip\" in zip_url]\n",
        "time.sleep(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD2zl1K0AKir"
      },
      "source": [
        "len(page_zip_urls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EnSCXKOARBC"
      },
      "source": [
        "Há um arquivo repetido, veremos adiante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rotWilpI-73s"
      },
      "source": [
        "# Importando as revistas\n",
        "from datetime import datetime\n",
        "start_time = datetime.now()\n",
        "for url in page_zip_urls:\n",
        "  print(\"Extraindo o pdf da url: \", url)\n",
        "  getRpm = 'wget --no-check-certificate -P ./ %s' %url\n",
        "  subprocess.run(getRpm, shell=True)\n",
        "end_time = datetime.now()\n",
        "print('\\n')\n",
        "print('Tempo total de importação das revistas: {}'.format(end_time - start_time))\n",
        "print(\"Processo finalizado!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8f-pfKARuii"
      },
      "source": [
        "Verificando o que temos no drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bxIUbbRRtMt"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFgLKaxTSiWK"
      },
      "source": [
        "# Como não faremos mais atividades de scrapping, vamos excluir os arquivos chromedriver, chromedriver_linux64.zip, bem como o arquivo repetido P2130.zip.1\n",
        "import os\n",
        "os.remove('chromedriver')\n",
        "os.remove('chromedriver_linux64.zip')\n",
        "os.remove('P2130.zip.1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc5Jr8i3S5sd"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MDlpuE_WNXi"
      },
      "source": [
        "import os \n",
        "os.chdir('../')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slZN-J1DW2EN"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch67wCSipGVe"
      },
      "source": [
        "Após o download de todas as rpi's no formato txt, vamos agora \"unzip\" todos os arquivos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQBoUTm0dWK9"
      },
      "source": [
        "# Função para \"unzip\" os arquivos zipados\n",
        "import zipfile\n",
        "def un_zipFiles(path):\n",
        "    files=os.listdir(path)\n",
        "    for file in files:\n",
        "        if file.endswith('.zip'):\n",
        "            filePath=path+'/'+file\n",
        "            zip_file = zipfile.ZipFile(filePath)\n",
        "            for names in zip_file.namelist():\n",
        "                zip_file.extract(names,path)\n",
        "            zip_file.close() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9JJKZ-NxbAM"
      },
      "source": [
        "# Chamando a função:\n",
        "path=\"TCC\"\n",
        "un_zipFiles(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxF2SnumXJL8"
      },
      "source": [
        "os.chdir(\"TCC\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X1l9vmTxPBk"
      },
      "source": [
        "Vamos deletar os arquivos .zip e .xml que ficaram na pasta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXV2EPv9xNF1"
      },
      "source": [
        "os.chdir('../')\n",
        "dir_name = \"TCC\"\n",
        "test = os.listdir(dir_name)\n",
        "\n",
        "for item in test:\n",
        "    if item.endswith(\".zip\") or item.endswith(\".xml\"):\n",
        "        os.remove(os.path.join(dir_name, item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0REsx3JiIbn"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcocGtw0YQQa"
      },
      "source": [
        "os.chdir(\"TCC\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33tYYoLb9q2v"
      },
      "source": [
        "# Contando o número de arquivos\n",
        "import glob\n",
        "j=0\n",
        "for x in glob.glob('*'):\n",
        "  if x.endswith(\".txt\") or x.endswith(\".TXT\"):\n",
        "   j=j+1\n",
        "j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNHeAl5GZKJo"
      },
      "source": [
        "Portanto, até aqui tudo ok! Temos ao todo 1453 rpi's no formato .txt!\n",
        "\n",
        "Encerramos a primeira parte do trabalho, que foi a coleta dos dados, vamos à segunda etapa!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hETWzod80fE"
      },
      "source": [
        "# **SEGUNDA ETAPA: ETL - Extraction, Transformation e Loading (extração, transformação e carregamento dos dados)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejilx39d_I9o"
      },
      "source": [
        "Nesta etapa, após o download de todas as RPI's, no período de 01/01/1993 a 08/12/2020, vamos extrair as informações contidas em alguns despachos, para a construção dos dataframes que serão utilizados nas Etapas seguintes. \n",
        "\n",
        "Estes dataframes serão detalhados mais adiante.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V510ssAMm_nC"
      },
      "source": [
        "# **1.   Extração**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN3Tv4Xlc3_W"
      },
      "source": [
        "Vamos visualizar o que há nos arquivos txt:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFgUS-f1ojW_"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqoVCqptFFsJ"
      },
      "source": [
        "# Tentando abrir com encoding utf-8\n",
        "# Abrindo o arquivo P1411  \n",
        "P1411 = open(\"P1411.txt\", encoding = \"utf-8\")\n",
        "print(P1411.read())\n",
        "P1411.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qi_6TEuFNlX"
      },
      "source": [
        "Com o encoding utf-8 deu erro, vamos tentar abrir com o encoding iso-8859-1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4irUwSeEbWuV"
      },
      "source": [
        "P1411 = open(\"P1411.txt\", encoding = \"iso-8859-1\")\n",
        "print(P1411.read())\n",
        "P1411.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip7Nkgbyinlh"
      },
      "source": [
        "# Abrindo o arquivo P2600\n",
        "P2600 = open(\"P2600.txt\", encoding = \"utf-8\")\n",
        "print(P2600.read())\n",
        "P2600.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wws4r5nBFlUp"
      },
      "source": [
        "Vimos que os arquivos podem abrir ou com o encoding utf-8 ou com o iso-8859-1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei3BV6_e5ZPf"
      },
      "source": [
        "Com base na estrutura sequencial de cada despacho, construíremos então três dataframes: \n",
        "\n",
        "\n",
        "1.   Dataframe com os Despachos 1.3 (PCT), 3.1 (Não PCT) e 3.2. O despacho 1.3 trata da publicação da entrada na fase nacional do pedido internacional depositado através do Tratado de Cooperação de Patentes - PCT, o despacho 3.1 refere-se à Publicação do Pedido de Patente ou de Certificado de Adição de Invenção e o despacho 3.2 informa a Publicação antecipada do pedido depositado, a requerimento do depositante. Neste dataframe, em cada coluna, teremos as seguintes informações:\n",
        "\n",
        "- idpedido: é o número do pedido de patente (21);\n",
        "\n",
        "- data_deposito: é a data do depósito (22) do pedido;\n",
        "\n",
        "- ipc: é a Classificação Internacional de Patentes (IPC, na sigla em inglês) (51);\n",
        "\n",
        "- titulo: é o Título (54) do pedido de patente;  \n",
        "\n",
        "- depositante: é o Depositante (71) do pedido de patente, podendo ser o inventor ou uma empresa. Esta informação também contém o país de origem do depositante, entre parênteses, que será desmembrada em outra coluna; \n",
        "\n",
        "- despacho: informando se o pedido teve a publicação 1.3, 3.1 ou 3.2; e\n",
        "\n",
        "- rpi: informa em qual revista foi publicado o despacho e a data da publicação da revista.\n",
        "\n",
        "\n",
        "2.   Um dataframe com os despachos 6.1, 6.20, 6.21, 6.22, 7.1 (os despachos com início 6 tratam de exigências formais/técnicas, a qual indica que há uma propenção a deferir o pedido de patente, isto é, o pedido tem chance de ter a patente concedida, e o 7.1 que é uma ciência a qual indica que há uma propenção a indeferir o pedido de patente (9.2), ou seja, o pedido pode não ter a concesssão da patente requerida). Em cada coluna, deverá conter as seguintes informações:\n",
        "\n",
        "- idpedido: é o número do pedido de patente (21);\n",
        "\n",
        "- data_deposito: é a data do depósito (22) do pedido;\n",
        "\n",
        "- depositante: é o Depositante (71) do pedido de patente, podendo ser o inventor ou uma empresa. Esta informação também contém o país de origem do depositante, entre parênteses, que será desmembrada em outra coluna; \n",
        "\n",
        "- despacho: informando os despachos; e\n",
        "\n",
        "- rpi: informa em qual revista foi publicado o despacho e a data da publicação da revista.\n",
        "\n",
        "\n",
        "3.   E, outro dataframe com os despachos 9.1, 9.2 e 11.2 (o 9.1 é a concessão da patente, o 9.2 é a não concessão da patente e o 11.2 é o arquivamento definitivo do pedido caso o depositante não responda à exigência/ciência no prazo de 90 dias). Neste dataframe, em cada coluna teremos as seguintes informações: \n",
        "\n",
        "- idpedido: é o número do pedido de patente (21);\n",
        "\n",
        "- data_deposito: é a data do depósito (22) do pedido;\n",
        "\n",
        "- titulo: é o Título (54) do pedido de patente;  \n",
        "\n",
        "- depositante: é o Depositante (71) do pedido de patente, podendo ser o inventor ou uma empresa. Esta informação também contém o país de origem do depositante, entre parênteses, que será desmembrada em outra coluna; \n",
        "\n",
        "- despacho: informando os despachos; e\n",
        "\n",
        "- rpi: informa em qual revista foi publicado o despacho e a data da publicação da revista."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlgqY-kCbebD"
      },
      "source": [
        "# Verificando o tipo da variável P2600\n",
        "type(P2600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_EF4nPN-dP9"
      },
      "source": [
        "P1411"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDpqHsEh-aFH"
      },
      "source": [
        "P2600"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKe8ZwhN9MUH"
      },
      "source": [
        "P2600[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VTnxW-Cb6FH"
      },
      "source": [
        "O tipo da variável P1411 ou P2600, que abriu o arquivo txt, é _io.TextIOWrapper, um arquivo objeto que, segundo a mensagem de erro acima, não possui índice, portanto não é possível iterar sob esta variável. Vamos então trasformar o arquivo em uma lista, a qual é possível a manipulação dos dados (linhas). \n",
        "\n",
        "Para tanto, vamos criar uma função para abrir o arquivo com encoding utf-8 ou com o iso-8859-1 e retornar o arquivo já transformado em uma lista:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o32k7m9w5QSt"
      },
      "source": [
        "# Vamos definir uma função para abrir os arquivos txt retornando o mesmo transformado em uma lista:\n",
        "# Nos testes acima, verifcou-se que alguns arquivos txt abrem com o encoding utf-8 e outros com o iso-8859-1\n",
        "def txtplista(t):\n",
        " try:\n",
        "   with open(t, encoding = \"utf-8\") as f:\n",
        "     list1 = [line.rstrip('\\n') for line in f]\n",
        " except:\n",
        "   with open(t, encoding = \"ISO-8859-1\") as f:\n",
        "     list1 = [line.rstrip('\\n') for line in f]\n",
        "\n",
        " f.close()\n",
        " return list1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGcU6GtHEDgy"
      },
      "source": [
        "lista1=txtplista(\"P1411.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ehijbNyXUfL"
      },
      "source": [
        "lista1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rw0VPvo_j9z"
      },
      "source": [
        "len(lista1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE6S8SRLnGct"
      },
      "source": [
        "Observa-se que somente o arquivo P1513 possui 8554 linhas, esta revista é a mais antiga rpi que temos em nossa pasta! Vamos ver quantas linhas há na revista mais recente, a P2600. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nivbPQdl5mX5"
      },
      "source": [
        "lista2=txtplista(\"P2600.txt\")\n",
        "len(lista2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lObIynrAmu3q"
      },
      "source": [
        "lista2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0gU4M5wDTU2"
      },
      "source": [
        "lista2[0][0:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH1Wc6mMzrea"
      },
      "source": [
        "Vamos conhecer um pouco mais sobre os arquivos txt que extraímos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAiMp08SYU9z"
      },
      "source": [
        "import glob\n",
        "\n",
        "l=1\n",
        "linhas=[]\n",
        "for x in glob.glob(\"*\"):\n",
        "  if x.endswith(\".txt\") or x.endswith(\".TXT\"):\n",
        "    lista=txtplista(x)\n",
        "    nlinhas=len(lista)\n",
        "    print('Nº de linhas da revista ',x,'=',nlinhas,\" arquivo:\",l)\n",
        "    linhas.append(nlinhas)\n",
        "  l=l+1\n",
        "print('\\n') \n",
        "print(\"Processo de verificação Finalizado!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbsr7qiwYVGQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "my_array = np.array(linhas)\n",
        "my_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLOea553YVML"
      },
      "source": [
        "print('O número médio de linhas dos arquivos é: ', my_array.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjU2ZYqCYVWQ"
      },
      "source": [
        "print('A mediana de número de linhas dos arquivos é: ', np.median(my_array))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ls8IqI01im-"
      },
      "source": [
        "print('O número máximo de linhas dos arquivos é: ', np.max(my_array))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGE1vfl81iqv"
      },
      "source": [
        "print('O número mínimo de linhas dos arquivos é: ', np.min(my_array))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Ho-R4Kr_4g"
      },
      "source": [
        "plt.hist(my_array, bins=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbcrTL036GGd"
      },
      "source": [
        "Vamos imprimir aleatoriamente 3 linhas de cada arquivo, para ter uma idéia do conteúdo de todos os arquivos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbJPmnfd5Kq-"
      },
      "source": [
        "import glob\n",
        "l=1\n",
        "linhas=[]\n",
        "for x in glob.glob(\"*\"):\n",
        "  lista=txtplista(x)\n",
        "  print('RPI nº:',x,\" revista:\",l)\n",
        "  try:\n",
        "    print(lista[0])\n",
        "    print(lista[200])\n",
        "    print(lista[5000])\n",
        "  except:\n",
        "    print(lista[0])\n",
        "    print(lista[50])\n",
        "    print(lista[130])\n",
        "  l=l+1\n",
        "  \n",
        "print('\\n') \n",
        "print(\"Processo de verificação Finalizado!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKVzHQ-d_vfO"
      },
      "source": [
        "Da verificação de todas as revistas acima, podemos identificar alguns padrões:\n",
        "\n",
        "- Na primeira linha de cada arquivo (linha 0) está o número da revista e a data de publicação da revista.\n",
        "\n",
        "- As linhas que possuem informações que serão extraídas possuem o formato (xx).\n",
        "\n",
        "- Cada despacho de interesse, 1.3 por exemplo, tem o formato '(Cd) 1.3'.\n",
        "\n",
        "E, como já verificado anteriormente, analisando dois arquivos completos, podemos observar a seguinte estrutura geral para os despachos 1.3, 3.1 e 3.2:\n",
        "\n",
        "(Cd) despacho\n",
        "\n",
        "(21) número do pedido de patente\n",
        "\n",
        "(22) data do depósito\n",
        "\n",
        "(51) ipc\n",
        "\n",
        "(54) título\n",
        "\n",
        "(71) depositante da patente + (país de residência do depositante)\n",
        "\n",
        "\n",
        "No entanto, não é sempre que a ordem após o despacho apresenta esta sequência, alguns pedidos possuem prioridade unionista cujo código é (30), um dado que não fará parte da análise. Outro dado que as RPI's mais antigas possuem é o resumo (código (57)), que segue logo após a linha do título e, infelizmente, nas RPI's mais recentes o resumo foi excluído e, portanto, não será utilizado para a análise. Além disso, nas RPI's mais recentes, além da ipc, o pedido também apresenta mais uma linha, com o código (52), que é a clissificação cpc, outro dado que também não é do nosso interesse. Em alguns pedidos, pode não ter a classificação (ipc), pode não ter título e pode não ter o nome do depositante também. O que dificulta mais o desenvolvimento de um código para a extração.\n",
        "\n",
        "Para outros despachos a estrutura é um pouco semelhante, mas com menos informações (linhas) sequenciais.\n",
        "\n",
        "Ao escrever o código para extrair as informações acima, deveremos levar estas diferenças em consideração. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8v_dGlO-PGX"
      },
      "source": [
        "Com base nas informações acima, vamos escrever os códigos de extração, dependendo do despacho publicado, e depois testá-los em três revistas escolhidas aleatoriamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHnvNvmU-35b"
      },
      "source": [
        "# função para extrair as informações dos códigos 1.3, 3.1 e 3.2\n",
        "def pedidos(list1):\n",
        "  \n",
        "  # Criando listas vazias\n",
        "  rpi=[]\n",
        "  despacho1=[]\n",
        "  idpedido =[] \n",
        "  data=[]\n",
        "  ipc=[]\n",
        "  titulo=[]\n",
        "  depositante=[]\n",
        "\n",
        "  \n",
        "  i=0  # linha da lista que será extraída a informação\n",
        "\n",
        "  \n",
        "  # Extração propriamente dita\n",
        "  for j in list1[:]:\n",
        "      nrpi=0\n",
        "      nrpi=list1[0]\n",
        "  \n",
        "      if list1[i][5:]  == '1.3':\n",
        "        \n",
        "        ndespacho1=0\n",
        "        npedido =0\n",
        "        ndata=0\n",
        "        nipc=0\n",
        "        ntitulo=0\n",
        "        ndepositante=0\n",
        "\n",
        "        ndespacho1=list1[i][5:]\n",
        "        npedido =list1[i+1][5:]\n",
        "        ndata=list1[i+2][5:]\n",
        "      \n",
        "           \n",
        "        # Este loop dentro do despacho é para verificar se o valor correto está sendo extraído\n",
        "        # Caso não encontre a informação, o valor entrará  na lista como definido acima\n",
        "        k=i+1\n",
        "        while list1[k][1:3] != 'Cd':\n",
        "           if list1[k][1:3]=='21':\n",
        "             npedido =list1[k][5:]\n",
        "           elif list1[k][1:3]=='22':  \n",
        "             ndata=list1[k][5:]\n",
        "           elif list1[k][1:3]=='51':\n",
        "             nipc=list1[k][5:]\n",
        "           elif list1[k][1:3]=='54':\n",
        "             ntitulo=list1[k][5:]\n",
        "           elif list1[k][1:3]=='71':\n",
        "             ndepositante=list1[k][5:]\n",
        "           k=k+1\n",
        "\n",
        "        # Caso a variável não seja encontrada ou seja vazia \"\", garantiremos que seja preenchida com 0          \n",
        "        if nrpi==\"\":\n",
        "           nrpi=0\n",
        "        elif ndespacho1==\"\":\n",
        "           ndespacho1=0\n",
        "        elif npedido == \"\":\n",
        "           npedido=0\n",
        "        elif ndata == \"\":\n",
        "           ndata=0\n",
        "        elif nipc==\"\":\n",
        "           nipc=0\n",
        "        elif ntitulo==\"\":\n",
        "           ntitulo=0\n",
        "        elif ndepositante == \"\":\n",
        "           ndepositante=0 \n",
        "                  \n",
        "        # append as listas\n",
        "        rpi.append(nrpi)\n",
        "        idpedido.append(npedido) \n",
        "        data.append(ndata) \n",
        "        ipc.append(nipc)\n",
        "        titulo.append(ntitulo)\n",
        "        depositante.append(ndepositante)\n",
        "        despacho1.append(ndespacho1)\n",
        "               \n",
        "\n",
        "      elif list1[i][5:]  == '3.1' or list1[i][5:]  == '3.2':\n",
        "        \n",
        "        ndespacho1=0\n",
        "        npedido =0\n",
        "        ndata=0\n",
        "        nipc=0\n",
        "        ntitulo=0\n",
        "        ndepositante=0\n",
        "\n",
        "        ndespacho1=list1[i][5:]\n",
        "        npedido =list1[i+1][5:]\n",
        "        ndata=list1[i+2][5:]\n",
        "                             \n",
        "        # Este loop dentro do despacho é para verificar se o valor correto está sendo extraído\n",
        "        # Caso não encontre, o valor entrará na lista como definido acima \n",
        "      \n",
        "        k=i+1 \n",
        "        while list1[k][1:3]!= 'Cd':\n",
        "           if list1[k][1:3]=='21':\n",
        "             npedido =list1[k][5:]\n",
        "           elif list1[k][1:3]=='22':  \n",
        "             ndata=list1[k][5:]\n",
        "           elif list1[k][1:3]=='51':\n",
        "             nipc=list1[k][5:]\n",
        "           elif list1[k][1:3]=='54':\n",
        "             ntitulo=list1[k][5:]\n",
        "           elif list1[k][1:3]=='71':\n",
        "             ndepositante=list1[k][5:]  \n",
        "           k=k+1\n",
        "          \n",
        "        # Caso a variável não seja encontrada ou seja vazia \"\", garantiremos que seja preenchida com 0          \n",
        "        if nrpi==\"\":\n",
        "           nrpi=0\n",
        "        elif ndespacho1==\"\":\n",
        "           ndespacho1=0\n",
        "        elif npedido == \"\":\n",
        "           npedido=0\n",
        "        elif ndata == \"\":\n",
        "           ndata=0\n",
        "        elif nipc==\"\":\n",
        "           nipc=0\n",
        "        elif ntitulo==\"\":\n",
        "           ntitulo=0\n",
        "        elif ndepositante == \"\":\n",
        "           ndepositante=0 \n",
        "\n",
        "        # append as listas\n",
        "        rpi.append(nrpi)\n",
        "        idpedido.append(npedido) \n",
        "        data.append(ndata) \n",
        "        ipc.append(nipc)\n",
        "        titulo.append(ntitulo)\n",
        "        depositante.append(ndepositante)\n",
        "        despacho1.append(ndespacho1)\n",
        "       \n",
        "      i=i+1\n",
        "        \n",
        "  # Transformando as listas em dataframe   \n",
        "  pedido=pd.DataFrame(idpedido,columns=['idpedido'])\n",
        "  data=pd.DataFrame(data,columns=['data_deposito'])\n",
        "  ipc=pd.DataFrame(ipc,columns=['ipc'])\n",
        "  titulo=pd.DataFrame(titulo,columns=['titulo'])\n",
        "  depositante=pd.DataFrame(depositante,columns=['depositante'])\n",
        "  despacho=pd.DataFrame(despacho1,columns=['despacho'])\n",
        "  rpi=pd.DataFrame(rpi,columns=['rpi'])\n",
        "\n",
        "  \n",
        "  # Juntando os dataframes\n",
        "  frames=[pedido,data,ipc,titulo,depositante,despacho,rpi]\n",
        "  pedido=pd.concat(frames, axis=1)\n",
        "    \n",
        "  return pedido"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rmlnh21-4BK"
      },
      "source": [
        "# função para extrair as informações dos códigos 6.1, 6.20, 6.21, 6.22, 7.1\n",
        "def exi_ci(list1):\n",
        "  # Criando listas vazias\n",
        "  rpi=[]\n",
        "  despacho1=[]\n",
        "  idpedido=[]\n",
        "  data=[]\n",
        "  depositante=[]\n",
        "\n",
        "  i=0\n",
        "\n",
        "\n",
        "  # Extração propriamente dita\n",
        "  for j in list1[:]: \n",
        "      nrpi=0\n",
        "      nrpi=list1[0]\n",
        "    \n",
        "      if list1[i][5:] == '6.1' or list1[i][5:]  == '7.1':\n",
        "        \n",
        "        ndespacho1=0\n",
        "        npedido =0\n",
        "        ndata=0\n",
        "        ndepositante=0\n",
        "\n",
        "        ndespacho1=list1[i][5:]\n",
        "        npedido =list1[i+1][5:]\n",
        "        ndata=list1[i+2][5:]\n",
        "   \n",
        "        # Este loop dentro do despacho é para verificar se o valor correto está sendo extraído\n",
        "        # Caso não encontre, o valor entrará na lista como definido acima \n",
        "      \n",
        "        k=i+1  \n",
        "        while list1[k][1:3]!= 'Cd':\n",
        "           if list1[k][1:3]=='21':\n",
        "             npedido =list1[k][5:]\n",
        "           elif list1[k][1:3]=='22':  \n",
        "             ndata=list1[k][5:]\n",
        "           elif list1[k][1:3]=='71':\n",
        "             ndepositante=list1[k][5:]  \n",
        "           k=k+1\n",
        "        \n",
        "        # Caso a variável não seja encontrada ou seja vazia \"\", garantiremos que seja preenchida com 0          \n",
        "        if nrpi==\"\":\n",
        "           nrpi=0\n",
        "        elif ndespacho1==\"\":\n",
        "           ndespacho1=0\n",
        "        elif npedido == \"\":\n",
        "           npedido=0\n",
        "        elif ndata == \"\":\n",
        "           ndata=0\n",
        "        elif ndepositante == \"\":\n",
        "           ndepositante=0  \n",
        "                  \n",
        "        # append as listas\n",
        "        idpedido.append(npedido) \n",
        "        data.append(ndata) \n",
        "        despacho1.append(ndespacho1)\n",
        "        depositante.append(ndepositante)\n",
        "        rpi.append(nrpi)\n",
        "\n",
        "      elif list1[i][5:]  == '6.20' or list1[i][5:] == '6.21' or list1[i][5:]  == '6.22':\n",
        "        \n",
        "        ndespacho1=0\n",
        "        npedido =0\n",
        "        ndata=0\n",
        "        ndepositante=0\n",
        "\n",
        "        ndespacho1=list1[i][5:]\n",
        "        npedido =list1[i+1][5:]\n",
        "        ndata=list1[i+2][5:]\n",
        "      \n",
        "        # Este loop dentro do despacho é para verificar se o valor correto está sendo extraído\n",
        "        # Caso não encontre, o valor entrará na lista como definido acima\n",
        "        \n",
        "        k=i+1  \n",
        "        while list1[k][1:3]!= 'Cd':\n",
        "           if list1[k][1:3]=='21':\n",
        "             npedido =list1[k][5:]\n",
        "           elif list1[k][1:3]=='22':  \n",
        "             ndata=list1[k][5:]\n",
        "           elif list1[k][1:3]=='71':\n",
        "             ndepositante=list1[k][5:]  \n",
        "           k=k+1\n",
        "\n",
        "        # Caso a variável não seja encontrada ou seja vazia \"\", garantiremos que seja preenchida com 0         \n",
        "        if nrpi==\"\":\n",
        "           nrpi=0\n",
        "        elif ndespacho1==\"\":\n",
        "           ndespacho1=0\n",
        "        elif npedido == \"\":\n",
        "           npedido=0\n",
        "        elif ndata == \"\":\n",
        "           ndata=0\n",
        "        elif ndepositante == \"\":\n",
        "           ndepositante=0  \n",
        "                    \n",
        "        # append as listas\n",
        "        idpedido.append(npedido) \n",
        "        data.append(ndata) \n",
        "        despacho1.append(ndespacho1)\n",
        "        depositante.append(ndepositante)\n",
        "        rpi.append(nrpi)  \n",
        "\n",
        "      i=i+1\n",
        "        \n",
        "  # Transformando as listas em dataframe   \n",
        "  pedido=pd.DataFrame(idpedido,columns=['idpedido'])\n",
        "  data=pd.DataFrame(data,columns=['datadeposito'])\n",
        "  despacho=pd.DataFrame(despacho1,columns=['despacho'])\n",
        "  depositante=pd.DataFrame(depositante,columns=['depositante'])\n",
        "  rpi=pd.DataFrame(rpi,columns=['rpi'])\n",
        "   \n",
        "  # Juntando os dataframes\n",
        "  frames=[pedido,data,depositante,despacho,rpi]\n",
        "  exigencia_ciencia=pd.concat(frames, axis=1)\n",
        "    \n",
        "  return exigencia_ciencia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1R9iGX--4Kw"
      },
      "source": [
        "def decisao(list1):\n",
        "  # Criando listas vazias\n",
        "  rpi=[]\n",
        "  despacho1=[]\n",
        "  idpedido=[]\n",
        "  data=[]\n",
        "  titulo=[]\n",
        "  depositante=[]\n",
        "  i=0\n",
        "\n",
        "  # Extração propriamente dita\n",
        "  for j in list1[:]: \n",
        "      nrpi=0\n",
        "      nrpi=list1[0]\n",
        "      \n",
        "      if list1[i][5:]  == '9.1' or list1[i][5:] == '9.2':\n",
        "        \n",
        "        ndespacho1=0\n",
        "        npedido =0\n",
        "        ndata=0\n",
        "        ntitulo=0\n",
        "        ndepositante=0\n",
        "\n",
        "        ndespacho1=list1[i][5:]\n",
        "        npedido =list1[i+1][5:]\n",
        "        ndata=list1[i+2][5:]\n",
        "\n",
        "        # Este loop dentro do despacho é para verificar se o valor correto está sendo extraído\n",
        "        # Caso não encontre, o valor entrará na lista como definido acima\n",
        "      \n",
        "        k=i+1 \n",
        "        while list1[k][1:3]!='Cd':\n",
        "           if list1[k][1:3]=='21':\n",
        "             npedido =list1[k][5:]\n",
        "           elif list1[k][1:3]=='22':  \n",
        "             ndata=list1[k][5:]\n",
        "           elif list1[k][1:3]=='54':  \n",
        "             ntitulo=list1[k][5:] \n",
        "           elif list1[k][1:3]=='71':\n",
        "             ndepositante=list1[k][5:]  \n",
        "           k=k+1\n",
        "\n",
        "        # Caso a variável não seja encontrada ou seja vazia \"\", garantiremos que seja preenchida com 0         \n",
        "        if nrpi==\"\":\n",
        "           nrpi=0\n",
        "        elif ndespacho1==\"\":\n",
        "           ndespacho1=0\n",
        "        elif npedido == \"\":\n",
        "           npedido=0\n",
        "        elif ndata == \"\":\n",
        "           ndata=0\n",
        "        elif ntitulo==\"\":\n",
        "           ntitulo=0\n",
        "        elif ndepositante == \"\":\n",
        "           ndepositante=0 \n",
        "                  \n",
        "        # append as listas\n",
        "        idpedido.append(npedido) \n",
        "        data.append(ndata) \n",
        "        titulo.append(ntitulo)\n",
        "        despacho1.append(ndespacho1)\n",
        "        depositante.append(ndepositante)\n",
        "        rpi.append(nrpi)\n",
        "        \n",
        "      elif list1[i][5:]  == '11.2':\n",
        "\n",
        "        ndespacho1=0\n",
        "        npedido =0\n",
        "        ndata=0\n",
        "        ndepositante=0\n",
        "\n",
        "        ndespacho1=list1[i][5:]\n",
        "        npedido =list1[i+1][5:]\n",
        "        ndata=list1[i+2][5:]\n",
        "        ntitulo=\"Sem título\"\n",
        "\n",
        "        # Este loop dentro do despacho é para verificar se o valor correto está sendo extraído\n",
        "        # Caso não encontre, o valor entrará na lista como definido acima\n",
        "      \n",
        "        k=i+1 \n",
        "        while list1[k][1:3]!= 'Cd':\n",
        "           if list1[k][1:3]=='21':\n",
        "             npedido =list1[k][5:]\n",
        "           elif list1[k][1:3]=='22':  \n",
        "             ndata=list1[k][5:]\n",
        "           elif list1[k][1:3]=='71':\n",
        "             ndepositante=list1[k][5:]  \n",
        "           k=k+1\n",
        "\n",
        "        # Caso a variável não seja encontrada ou seja vazia \"\", garantiremos que seja preenchida com 0          \n",
        "        if nrpi==\"\":\n",
        "           nrpi=0\n",
        "        elif ndespacho1==\"\":\n",
        "           ndespacho1=0\n",
        "        elif npedido == \"\":\n",
        "           npedido=0\n",
        "        elif ndata == \"\":\n",
        "           ndata=0\n",
        "        elif ndepositante == \"\":\n",
        "           ndepositante=0\n",
        "\n",
        "        # append as listas\n",
        "        idpedido.append(npedido) \n",
        "        data.append(ndata) \n",
        "        titulo.append(ntitulo)\n",
        "        despacho1.append(ndespacho1)\n",
        "        depositante.append(ndepositante)\n",
        "        rpi.append(nrpi)\n",
        "        \n",
        "\n",
        "      i=i+1\n",
        "        \n",
        "  # Transformando as listas em dataframe   \n",
        "  pedido=pd.DataFrame(idpedido,columns=['idpedido'])\n",
        "  data=pd.DataFrame(data,columns=['data_deposito'])\n",
        "  titulo=pd.DataFrame(titulo,columns=['titulo'])\n",
        "  despacho=pd.DataFrame(despacho1,columns=['despacho'])\n",
        "  depositante=pd.DataFrame(depositante,columns=['depositante'])\n",
        "  rpi=pd.DataFrame(rpi,columns=['rpi'])\n",
        "   \n",
        "  # Juntando os dataframes\n",
        "  frames=[pedido,data,titulo,depositante,despacho,rpi]\n",
        "  dec=pd.concat(frames, axis=1)\n",
        "    \n",
        "  return dec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFkRSZqTNbxi"
      },
      "source": [
        "Vamos verificar a quantidade de despachos 1.3, 3.1 e 3.2 nas rpi's P1527.txt, P2080.txt e P2592.txt:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clVu3IlvBRbb"
      },
      "source": [
        "lista1=txtplista('P1527.txt')\n",
        "lista2=txtplista('P2080.txt')\n",
        "lista3=txtplista('P2592.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2b6nw1qNoGU"
      },
      "source": [
        "# Verificando a quantidade de despachos 1.3, 3.1 e 3.2 nas revistas escolhidas para saber o número total de linhas que o dataframe deverá ter:\n",
        "print('Revista P1527: ')\n",
        "print(\"Nº de despachos 1.3:\", lista1.count('(Cd) 1.3'))\n",
        "print('Nº de despachos 3.1:', lista1.count('(Cd) 3.1'))\n",
        "print('Nº de despachos 3.2', lista1.count('(Cd) 3.2'))\n",
        "print('Número total de linhas que o dataframe deverá ter:', lista1.count('(Cd) 1.3')+lista1.count('(Cd) 3.1')+lista1.count('(Cd) 3.2'))\n",
        "print('')\n",
        "print('Revista P2080: ')\n",
        "print(\"Nº de despachos 1.3:\", lista2.count('(Cd) 1.3'))\n",
        "print('Nº de despachos 3.1:', lista2.count('(Cd) 3.1'))\n",
        "print('Nº de despachos 3.2:', lista2.count('(Cd) 3.2'))\n",
        "print('Número total de linhas que o dataframe deverá ter:', lista2.count('(Cd) 1.3')+lista2.count('(Cd) 3.1')+lista2.count('(Cd) 3.2'))\n",
        "print('')\n",
        "print('Revista P2592: ')\n",
        "print(\"Nº de despachos 1.3:\", lista3.count('(Cd) 1.3'))\n",
        "print('Nº de despachos 3.1:', lista3.count('(Cd) 3.1'))\n",
        "print('Nº de despachos 3.2:', lista3.count('(Cd) 3.2'))\n",
        "print('Número total de linhas que o dataframe deverá ter:', lista3.count('(Cd) 1.3')+lista3.count('(Cd) 3.1')+lista3.count('(Cd) 3.2'))\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfhIjGFfOrKz"
      },
      "source": [
        "Testando a função pedidos (extração dos códigos 1.3, 3.1 e 3.2):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHw9K-BGNoPu"
      },
      "source": [
        "print(pedidos(lista1).to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEz7khpsOsYG"
      },
      "source": [
        "pedidos(lista1).describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MICVyh-lQYH1"
      },
      "source": [
        "pedidos(lista1).info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwMEEubgOsgg"
      },
      "source": [
        "print(pedidos(lista2).to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndjkAjsfNoJQ"
      },
      "source": [
        "pedidos(lista2).describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGtsz_DpPvu2"
      },
      "source": [
        "pedidos(lista2).info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pSw-UcuPvx-"
      },
      "source": [
        "print(pedidos(lista3).to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KiiQc4DPv1y"
      },
      "source": [
        "pedidos(lista3).describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "852jcrcnaop8"
      },
      "source": [
        "pedidos(lista3).info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9NKf93TSeOr"
      },
      "source": [
        "No teste de extração da RPI 1527 com a função pedidos, falhas foram identificadas após a extração, pois na coluna de idpedido em que deveria haver somente os números dos pedidos, na linha 5 havia trecho de textos. A mesma falha foi identificada na coluna data_deposito, em que foram encontrados textos em 3 linhas, onde deveria haver somente datas. Não foram identificados erros de extração nas outras colunas.\n",
        "\n",
        "Observou-se que o erro na extração ocorreu porque em alguns registros, os títulos ou resumos apresentam continuidade de texto nas linhas seguintes, sendo que, coincidentemente, algumas destas continuações se iniciam com caracteres semelhantes a caracteres iniciais que contém o idpedido ou a data_depósito que se iniciam com (21) e (22), respectivamente. Portanto, para mitigar o erro de extração vamos procurar padrões mais específicos relativos às informações de interesse no sentido de criar um código que possa extrair os registros com acurácia.\n",
        "\n",
        "Desta forma, no intuito de identificar estes padrões específicos, podemos verificar como aparecem os registros entre parênteses (..) que são números ou letras.\n",
        "\n",
        "Verificaremos a seguir com mais profundidade o formato dos cógidos de todas as revistar para identificar alguns padrões e exceções destes padrões."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ3qYOKsTZTa"
      },
      "source": [
        "# Criando uma função para remover espaços no início e fim de cada linha da string\n",
        "def remove_(list1):\n",
        "  i=0\n",
        "  ni=0\n",
        "  list2=[]\n",
        "  for i in list1:\n",
        "    i = i.lstrip()\n",
        "    ni = i.rstrip()\n",
        "    list2.append(ni)\n",
        "  return list2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjpeIrgSH8K8"
      },
      "source": [
        "import glob\n",
        "\n",
        "l=1\n",
        "codigos=[]\n",
        "rpi1=[]\n",
        "rpi2=[]\n",
        "for x in glob.glob(\"*\"):\n",
        "  if x.endswith(\".txt\") or x.endswith(\".TXT\"):\n",
        "    lista=txtplista(x)\n",
        "    lista=remove_(lista)\n",
        "    rpi1.append(lista[0])\n",
        "    for i in lista:\n",
        "      if (i[0:1]=='(' or i[0:1]==')') and (i[1:3].isnumeric()==True or i[1:3].isalpha()==True):\n",
        "        n=i[0:5]\n",
        "        codigos.append(n)\n",
        "        rpi2.append(lista[0])\n",
        "    print('rpi:',lista[0],\" arquivo:\",l)\n",
        "    l=l+1\n",
        "print('\\n') \n",
        "print(\"Processo de verificação Finalizado!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFnvs6SZgVUG"
      },
      "source": [
        "import os\n",
        "os.remove('P2236.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXe4Uuf-qj-p"
      },
      "source": [
        "f1=pd.DataFrame(codigos,columns=['codigos'])\n",
        "f2=pd.DataFrame(rpi2,columns=['rpi'])\n",
        "frames=[f2,f1]\n",
        "cod_rpi=pd.concat(frames, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2bf54r1rJsb"
      },
      "source": [
        "editado=cod_rpi[['codigos', 'rpi']].groupby('codigos').agg(lambda x: list(set(x))).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rIhAH7OtIfT"
      },
      "source": [
        "print(editado.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBSYgf6CNpSj"
      },
      "source": [
        "Da visualização acima concluímos que em todos os arquivos txt, na linha 0 consta o número da rpi e a data de publicação. Também é notório que há uma algumas variações na forma em que a informação foi registrada no arquivo txt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK4GkB9y_hV5"
      },
      "source": [
        "Outros padrões foram identificados e vamos utilizá-los para melhorar a extração e evitar dados indesejáveis:\n",
        "\n",
        "- Após o código do nº do pedido (21) o pedido sempre se inicia com letra maiuscula;\n",
        "\n",
        "- Após o código da data de depósito (22) a data sempre se inicia com um número;\n",
        "\n",
        "- Após o código da ipc (51), a classificação sempre é grafada em letra maiúscula;\n",
        "\n",
        "- O título, após o código (54), sempre se inicia com uma letra maiúscula, ou outro símbolo que não uma letra.\n",
        "\n",
        "Percebe-se também que pode-se extrair tudo utilizando apenas uma função, mas para essa única função funcionar, precisamos tirar todos os espaços do início e do fim de cada linha da lista criada a partir de cada arquivo txt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpNWGfCQMLVU"
      },
      "source": [
        "Algumas variações no registro da informação (Cd):\n",
        "\n",
        "- 538 '(cd) ' [No. 1541 de 18/07/2000, No. 1539 04/07/2000, No. 1540 11/07/2000]\n",
        "\n",
        "- 300 '(Cd) ' [No 2474 de 05/06/2018, No 2060 de 29/06/2010, ...]\n",
        "\n",
        "- 280 '(CD) ' [No. 1809 06/09/2005, No. 1811 20/09/2005, ...]\n",
        "\n",
        "Assim, as linhas da lista que possuem os digitos cd, podem assumir as formas vistas acima. Para contornar esta não padronização nos registros, vamos criar uma função para transformar todos os dígitos alphanuméricos entre () que estão no início de cada linha da lista para caixa alta:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHUFt314MgeX"
      },
      "source": [
        "def c_alta(list1):\n",
        "  i=0\n",
        "  ni=0\n",
        "  list2=[]\n",
        "  for i in list1:\n",
        "    if i[0:1]=='(' and i[1:3].isalpha()==True:\n",
        "      ni=i.upper()\n",
        "    else:\n",
        "      ni=i  \n",
        "    list2.append(ni)\n",
        "  return list2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73YDjdSy1NVc"
      },
      "source": [
        "lista1=txtplista('P2236.txt')\n",
        "lista1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOJFMVb5OsJE"
      },
      "source": [
        "c_alta(lista1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqQ5BSwbIBwz"
      },
      "source": [
        "Modificando o código de extração com base nas observações anteriores. \n",
        "Teremos que extrair os dados dos despachos 2.4 ou 23.1.1 também, pois são pedidos divididos, juntamente com o número do pedido original, para posterior extração dos dados bibliográficos dos pedidos originais, que são os mesmos, podendo o título e/ou classificação serem os mesmos ou serem distintos, não haverá como obter estes dados. Outro dado, não menos importante, que temos que levar em consideração é o fato de que os números dos pedidos podem ser alterados por conta de mudança da natureza (patente de invenção para patente de modelo de utilidade ou vice-versa) ou por ter sido publicada com numeração indevida. Para extrair estes dados, a função de extração retornará um dataframe com o número do pedido e a nova numeração, para posterior ajuste dos dataframes principais.\n",
        "\n",
        "Os despachos que publicam a nova numeração do pedido são 15.10, 15.12 e 51.\n",
        "\n",
        "Vamos mudar um pouco a estratégia de estração, ao invés de termos três funções, vamos criar apenas uma, que retornará 3 dataframes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwEtJcnSS8c7"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKZm9-EpIGRT"
      },
      "source": [
        "# função para extrair as informações dasRPI’s e transformar estar informações em 3 dataframes  \n",
        "def pedidos(list1):\n",
        "  \n",
        "  # Criando listas vazias\n",
        "  data_rpi=[]\n",
        "  despacho1=[]\n",
        "  idpedido =[] \n",
        "  data=[]\n",
        "  original=[]\n",
        "  ipc=[]\n",
        "  titulo=[]\n",
        "  depositante=[]\n",
        "  \n",
        "  data_rpi2=[]\n",
        "  despacho2=[]\n",
        "  idpedido2=[]\n",
        "  depositante2=[]\n",
        "  data2=[]\n",
        "\n",
        "  data_rpi3=[]\n",
        "  despacho3=[]\n",
        "  idpedido3=[]\n",
        "  novo_numero=[]\n",
        "\n",
        "  ndata_rpi=''\n",
        "  # vamos trabalhar apenas com a data de publicação da rpi\n",
        "  # a linha abaixo retorna apenas os últimos caracteres da linha 0 da lista\n",
        "  ndata_rpi=list1[0][list1[0].rindex(' ')+1:] \n",
        "\n",
        "  ndata_rpi2=''\n",
        "  ndata_rpi2=ndata_rpi \n",
        "  \n",
        "  ndata_rpi3=''\n",
        "  ndata_rpi3=ndata_rpi \n",
        " \n",
        "  i=0  # linha da lista que será extraída a informação\n",
        "  be=0\n",
        "  ce=0\n",
        "  de=0\n",
        "\n",
        "  # Extração propriamente dita\n",
        "  for j in list1:\n",
        "      b=['(CD) 1.3','(CD) 3.1','(CD) 3.2','(CD) 2.4','(CD) 23.1.1']\n",
        "      if j in b:\n",
        "        if list1[i+1][5:7]=='PI' or list1[i+1][5:7]=='MU' or list1[i+1][5:6]=='C' or list1[i+1][5:7]=='BR':\n",
        "          be+=1 # contagem dos pedidos com despachos contidos em b\n",
        "          ndespacho1=''\n",
        "          npedido =''\n",
        "          ndata=''\n",
        "          noriginal=''\n",
        "          nipc=''\n",
        "          ntitulo=''\n",
        "          ndepositante=''\n",
        "\n",
        "          ndespacho1=list1[i][5:]\n",
        "                   \n",
        "          # Este loop dentro do despacho é para verificar se o valor correto está sendo extraído\n",
        "          k=i+1\n",
        "          while list1[k][0:5] != '(CD) ':\n",
        "             if list1[k][0:5]=='(21) ' and list1[k][5:6].isupper()==True:\n",
        "               npedido =list1[k][5:]\n",
        "             elif list1[k][0:5]=='(22) ' and list1[k][5:6].isnumeric()==True:\n",
        "               ndata=list1[k][5:]\n",
        "             elif list1[k][0:5]=='(62) ' and list1[k][5:6].isupper()==True:\n",
        "               noriginal=list1[k][5:]\n",
        "             elif list1[k][0:5]=='(51) ' and list1[k][5:6].isupper()==True:\n",
        "               nipc=list1[k][5:]\n",
        "             elif list1[k][0:5]=='(54) ' and (list1[k][5:6].isalpha()==False or list1[k][5:6].isupper()==True):\n",
        "               ntitulo=list1[k][5:]\n",
        "             elif list1[k][0:5]=='(71) ': \n",
        "               ndepositante=list1[k][5:]\n",
        "             k+=1\n",
        "\n",
        "                  \n",
        "          # append as listas\n",
        "          data_rpi.append(ndata_rpi)\n",
        "          idpedido.append(npedido) \n",
        "          data.append(ndata)\n",
        "          original.append(noriginal) \n",
        "          ipc.append(nipc)\n",
        "          titulo.append(ntitulo)\n",
        "          depositante.append(ndepositante)\n",
        "          despacho1.append(ndespacho1)         \n",
        "\n",
        "      c=['(CD) 6.1','(CD) 6.20','(CD) 6.21','(CD) 6.22','(CD) 7.1','(CD) 8.6','(CD) 8.11','(CD) 8.12','(CD) 9.1','(CD) 9.2','(CD) 11.1.1','(CD) 11.2', '(CD) 11.4', '(CD) 11.5','(CD) 11.6','(CD) 11.11','(CD) 11.18','(CD) 11.30','(CD) 11.31']\n",
        "      if j in c:\n",
        "        if list1[i+1][5:7]=='PI' or list1[i+1][5:7]=='MU' or list1[i+1][5:6]=='C' or list1[i+1][5:7]=='BR':\n",
        "          ce+=1 # contagem dos pedidos com despachos contidos em c\n",
        "          ndespacho2=''\n",
        "          npedido2 =''\n",
        "          ndata2=''\n",
        "          ndepositante2=''\n",
        "          ndespacho2=list1[i][5:]\n",
        "          \n",
        "          # Este loop dentro do despacho é para verificar se o valor correto está sendo extraído\n",
        "          k=i+1\n",
        "          while list1[k][0:5] != '(CD) ':\n",
        "             if list1[k][0:5]=='(21) ' and list1[k][5:6].isupper()==True:\n",
        "               npedido2 =list1[k][5:]\n",
        "             elif list1[k][0:5]=='(22) ' and list1[k][5:6].isnumeric()==True:\n",
        "               ndata2=list1[k][5:]\n",
        "             elif list1[k][0:5]=='(71) ': \n",
        "               ndepositante2=list1[k][5:]\n",
        "             k+=1\n",
        "\n",
        "          # append as listas\n",
        "          data_rpi2.append(ndata_rpi2)\n",
        "          idpedido2.append(npedido2)\n",
        "          depositante2.append(ndepositante2)\n",
        "          data2.append(ndata2) \n",
        "          despacho2.append(ndespacho2)\n",
        "\n",
        "      d=['(CD) 15.10','(CD) 15.12','(CD) 51']\n",
        "      if j in d:\n",
        "        if list1[i+1][5:7]=='PI' or list1[i+1][5:7]=='MU' or list1[i+1][5:6]=='C' or list1[i+1][5:7]=='BR':\n",
        "          de+=1 # contagem dos pedidos com despachos contidos em d\n",
        "          ndespacho3=''\n",
        "          npedido3 =''\n",
        "          nnovo_numero=''\n",
        "          \n",
        "          # Este loop dentro do despacho é para verificar se o valor correto está sendo extraído\n",
        "          k=i+1\n",
        "          while list1[k][0:5] != '(CD) ':\n",
        "             if list1[k][0:5]=='(21) ' and list1[k][5:6].isupper()==True:\n",
        "               npedido3 =list1[k][5:]\n",
        "             elif list1[k][0:5]=='(CO) ':\n",
        "               nnovo_numero=list1[k][5:]\n",
        "             k+=1\n",
        "          # append as listas\n",
        "          data_rpi3.append(ndata_rpi3)\n",
        "          idpedido3.append(npedido3)\n",
        "          novo_numero.append(nnovo_numero)\n",
        "\n",
        "      i+=1\n",
        "        \n",
        "  # Transformando as listas em dataframe   \n",
        "  pedido=pd.DataFrame(idpedido,columns=['idpedido'])\n",
        "  data=pd.DataFrame(data,columns=['data_deposito'])\n",
        "  original=pd.DataFrame(original,columns=['original'])\n",
        "  ipc=pd.DataFrame(ipc,columns=['ipc'])\n",
        "  titulo=pd.DataFrame(titulo,columns=['titulo'])\n",
        "  depositante=pd.DataFrame(depositante,columns=['depositante'])\n",
        "  despacho=pd.DataFrame(despacho1,columns=['despacho'])\n",
        "  data_rpi=pd.DataFrame(data_rpi,columns=['data_rpi'])\n",
        "\n",
        "  pedido2=pd.DataFrame(idpedido2,columns=['idpedido'])\n",
        "  depositante2=pd.DataFrame(depositante2,columns=['depositante'])\n",
        "  data2=pd.DataFrame(data2,columns=['data_deposito'])\n",
        "  despacho2=pd.DataFrame(despacho2,columns=['despacho'])\n",
        "  data_rpi2=pd.DataFrame(data_rpi2,columns=['data_rpi'])\n",
        "\n",
        "  pedido3=pd.DataFrame(idpedido3,columns=['idpedido'])\n",
        "  novo_numero=pd.DataFrame(novo_numero,columns=['novo_numero'])\n",
        "  data_rpi3=pd.DataFrame(data_rpi3,columns=['data_rpi'])\n",
        "  \n",
        "  # Juntando os dataframes\n",
        "  frames=[pedido,data,original,ipc,titulo,depositante,despacho,data_rpi]\n",
        "  pedido=pd.concat(frames, axis=1)\n",
        "\n",
        "  frames2=[pedido2,data2,depositante2,despacho2,data_rpi2]\n",
        "  outros=pd.concat(frames2, axis=1)\n",
        "\n",
        "  frames3=[pedido3,novo_numero,data_rpi3]\n",
        "  nova_num=pd.concat(frames3, axis=1)\n",
        "    \n",
        "  return pedido,outros,nova_num,be,ce,de"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYc1_OyXO1dI"
      },
      "source": [
        "Testando novamente a função pedidos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a76qcvieIGgi"
      },
      "source": [
        "lista1=txtplista('P1527.txt')\n",
        "lista1=remove_(lista1)\n",
        "lista1=c_alta(lista1)\n",
        "lista2=txtplista('P2080.txt')\n",
        "lista2=remove_(lista2)\n",
        "lista2=c_alta(lista2)\n",
        "lista3=txtplista('P2592.txt')\n",
        "lista3=remove_(lista3)\n",
        "lista3=c_alta(lista3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0VvRT0m8P-7"
      },
      "source": [
        "# Verificando a quantidade de despachos 1.3, 3.1 e 3.2 nas revistas escolhidas para saber o número total de linhas que o dataframe deverá ter:\n",
        "print('Revista P1527: ')\n",
        "print(\"Nº de despachos 1.3:\", lista1.count('(CD) 1.3'))\n",
        "print('Nº de despachos 3.1:', lista1.count('(CD) 3.1'))\n",
        "print('Nº de despachos 3.2', lista1.count('(CD) 3.2'))\n",
        "print('Nº de despachos 2.4', lista1.count('(CD) 2.4'))\n",
        "print('Nº de despachos 23.1.1', lista1.count('(CD) 23.1.1'))\n",
        "print('Número total de linhas que o dataframe deverá ter:', lista1.count('(CD) 1.3')+lista1.count('(CD) 3.1')+lista1.count('(CD) 3.2')+lista1.count('(CD) 2.4')+lista1.count('(CD) 23.1.1'))\n",
        "print('')\n",
        "print('Revista P2080: ')\n",
        "print(\"Nº de despachos 1.3:\", lista2.count('(CD) 1.3'))\n",
        "print('Nº de despachos 3.1:', lista2.count('(CD) 3.1'))\n",
        "print('Nº de despachos 3.2:', lista2.count('(CD) 3.2'))\n",
        "print('Nº de despachos 2.4', lista2.count('(CD) 2.4'))\n",
        "print('Nº de despachos 23.1.1', lista2.count('(CD) 23.1.1'))\n",
        "print('Número total de linhas que o dataframe deverá ter:', lista2.count('(CD) 1.3')+lista2.count('(CD) 3.1')+lista2.count('(CD) 3.2')+lista2.count('(CD) 2.4')+lista2.count('(CD) 23.1.1'))\n",
        "print('')\n",
        "print('Revista P2592: ')\n",
        "print(\"Nº de despachos 1.3:\", lista3.count('(CD) 1.3'))\n",
        "print('Nº de despachos 3.1:', lista3.count('(CD) 3.1'))\n",
        "print('Nº de despachos 3.2:', lista3.count('(CD) 3.2'))\n",
        "print('Nº de despachos 2.4', lista3.count('(CD) 2.4'))\n",
        "print('Nº de despachos 23.1.1', lista3.count('(CD) 23.1.1'))\n",
        "print('Número total de linhas que o dataframe deverá ter:', lista3.count('(CD) 1.3')+lista3.count('(CD) 3.1')+lista3.count('(CD) 3.2')+lista3.count('(CD) 2.4')+lista3.count('(CD) 23.1.1'))\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyqG1hFpPGRM"
      },
      "source": [
        "import pandas as pd\n",
        "total,outros,nova_num,a,b,c = pedidos(lista1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f53IGiHYLmU"
      },
      "source": [
        "print(total.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqbD37PWaX0L"
      },
      "source": [
        "print(outros.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1SefMc0iiMq"
      },
      "source": [
        "print(nova_num.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdFw-hBQ6Ote"
      },
      "source": [
        "print(a,'',b,'',c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DAAdBb5G3Fa"
      },
      "source": [
        "total, outros,nova_num,a,b,c=pedidos(lista2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46c5nfZneK4W"
      },
      "source": [
        "print(total.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZYot4MuajIA"
      },
      "source": [
        "print(outros.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nzGWZXIi0rj"
      },
      "source": [
        "print(nova_num.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjDFx-U26mM6"
      },
      "source": [
        "print(a,'',b,'',c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjBjG2OgasLh"
      },
      "source": [
        "total, outros,nova_num,a,b,c=pedidos(lista3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xhk8bTnasQ5"
      },
      "source": [
        "print(total.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTf_EjIRasUi"
      },
      "source": [
        "print(outros.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC9o4yzJjBUO"
      },
      "source": [
        "print(nova_num.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_dj3cIylVwu"
      },
      "source": [
        "Este último teste confirma que a função pedidos realiza a extração das informações de forma adequada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOTpolka-E9U"
      },
      "source": [
        "Agora, após as verificações mostrarem que a função extraiu as informações de forma adequada, vamos extrair as informações de todos os arquivos txt que temos na pasta. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGCzjMdKohIW"
      },
      "source": [
        "Aplicando a função de extração arquivo por arquivo, guardando cada dataframe gerado em uma lista para depois concatenar todos os dataframes e, por fim, salvar os dataframes em um formato csv:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcz1UBlG5O66"
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "from datetime import datetime\n",
        "\n",
        "ped_pub=[]\n",
        "outros=[]\n",
        "nova_num=[]\n",
        "xl=[]\n",
        "al=[]\n",
        "a1=0\n",
        "b1=0\n",
        "c1=0\n",
        "start_time = datetime.now()\n",
        "l=1\n",
        "for x in glob.glob(\"*\"):\n",
        "  if x.endswith(\".txt\") or x.endswith(\".TXT\"):\n",
        "    lista1=[]\n",
        "    # Abrindo o arquivo e transformando-o em uma lista\n",
        "    lista1=txtplista(x)\n",
        "    # Tirando os espaços do início e do fim de cada linha da lista\n",
        "    lista1=remove_(lista1)\n",
        "    # Passando todos os registros (cd) ou (co) para caixa alta\n",
        "    lista1=c_alta(lista1)\n",
        "    # Extraindo as informações e salvando-as em 2 dataframes\n",
        "    df1,df2,df3,a,b,c=pedidos(lista1)\n",
        "    # append os df\n",
        "    ped_pub.append(df1)\n",
        "    outros.append(df2)\n",
        "    nova_num.append(df3)\n",
        "    xl.append(x)\n",
        "    al.append(a)\n",
        "\n",
        "    a1=a1+a\n",
        "    b1=b1+b\n",
        "    c1=c1+c\n",
        "\n",
        "    print('Extraindo os dados do arquivo',x,'... ',' Nº de 1.3, 3.1, 3.2, 2.4 e 23.1.1:',a,' Arquivo nº:',l)\n",
        "    l+=1\n",
        "end_time = datetime.now()\n",
        "\n",
        "print('\\n')\n",
        "print('Total de linhas do dataframe com publicações 1.3, 3.1, 3.2, 2.4 e 23.1.1: ', a1)\n",
        "\n",
        "print('\\n')\n",
        "print('Total de linhas do dataframe com outras publicações: ', b1)\n",
        "\n",
        "print('\\n')\n",
        "print('Total de linhas do dataframe com pedidos renumerados: ', c1)\n",
        "\n",
        "print('\\n')\n",
        "print('Tempo de extração das informações: {}'.format(end_time - start_time))\n",
        "\n",
        "# Concatenando os df\n",
        "print('\\n')\n",
        "print('Concatenando os dataframes...')\n",
        "xdf = pd.DataFrame({'rpi':xl})\n",
        "adf = pd.DataFrame({'qtd_pub':al})\n",
        "fr=[xdf,adf]\n",
        "xdfadf=pd.concat(fr, axis=1)\n",
        "dep_pub_total=pd.concat(ped_pub,ignore_index=True)\n",
        "outros_total=pd.concat(outros,ignore_index=True)\n",
        "nova_num_total=pd.concat(nova_num,ignore_index=True)\n",
        "\n",
        "# Salvando os dataframes no formato csv\n",
        "print('\\n')\n",
        "print('Salvando os dataframes no formato csv...')\n",
        "xdfadf.to_csv(\"xdfadf.csv\", index=False)\n",
        "dep_pub_total.to_csv(\"dep_pub_total.csv\", index=False)\n",
        "outros_total.to_csv(\"outros_total.csv\", index=False) \n",
        "nova_num_total.to_csv(\"nova_num_total.csv\", index=False) \n",
        "\n",
        "print('\\n')\n",
        "print('Documentos salvos na pasta!')\n",
        "print('\\n') \n",
        "print(\"Processo de extração Finalizado!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acGpl_5AST3B"
      },
      "source": [
        "Os dataframes estão salvos na pasta! Vamos visualizar os dataframes gerados e fazer algumas verificações:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuS_IHDlnTmO"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzbPpVXzr5da"
      },
      "source": [
        "import pandas as pd\n",
        "xdfadf=pd.read_csv('xdfadf.csv')\n",
        "xdfadf.sort_values(by=['qtd_pub']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk0BnnfRtJ8N"
      },
      "source": [
        "Após verificar as revistas que constam 0 no número de pedidos publicados com despachos 1.3, 3.1, 3.2 e 3.4, constatamos que as RPI's 2119\te 2118\tpossuem sim estes despachos publicados, não nos arquivos txt, mas somente nos arquivos pdf publicados.\n",
        "\n",
        "Foi verificado que as outras RPI's que constam 0 nas publicações, realmente não possuem os citados despachos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOgE5KdZZ9C5"
      },
      "source": [
        "Vamos readaptar a função para extração dos dados somente para estas duas revistas. Dado que ao extrair os textos dos arquivos pdf o arquivo contendo o texto será diferente do arquivo txt extraído do website do INPI.\n",
        "\n",
        "Para extrair os dados de interesse vamos utilizar a biblioteca Apache Tika para a extração de texto de arquivos pdf, pois foi o método que demonstrou melhor extração após um teste rápido com as bibliotecas PyPDF2, Tabula, PDFMiner e o próprio Apache Tika.\n",
        "\n",
        "Vamos ao código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fepxJSr341FI"
      },
      "source": [
        "# Instalando a biblioteca Apache Tika\n",
        "!pip install tika"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIhJ-xu-41Qj"
      },
      "source": [
        "from tika import parser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K5_Lkzy41Vd"
      },
      "source": [
        "# Extraindo o texto do pdf...\n",
        "dados_pdf1 = parser.from_file('PATENTES2118.pdf')\n",
        "arquivo_txt1 = dados_pdf1['content']\n",
        "\n",
        "dados_pdf2 = parser.from_file('PATENTES2119.pdf')\n",
        "arquivo_txt2 = dados_pdf2['content']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUYvvzUy41Zi"
      },
      "source": [
        "# Formatando as linhas \n",
        "textlines1 = [textline1 for textline1 in arquivo_txt1.splitlines() if textline1 != '' and textline1 != ' ']\n",
        "textlines2 = [textline2 for textline2 in arquivo_txt2.splitlines() if textline2 != '' and textline2 != ' ']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxGjkcjI41dn"
      },
      "source": [
        "# Tirando os espaços do início e do fim de cada linha da lista\n",
        "l2118=remove_(textlines1)\n",
        "l2119=remove_(textlines2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19waUhGVCY8y"
      },
      "source": [
        "l2118"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqpvPszoShY7"
      },
      "source": [
        "l2119"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mw5kC5GNZ2n"
      },
      "source": [
        "Vamos mudar a estratégia de extração, fazendo uma adaptação no algoritmo de extração:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ySIz83YH7fE"
      },
      "source": [
        "# função para extrair as informações das RPI’s 2118 e 2119  \n",
        "def restante(list1,data_rpi1):\n",
        "  \n",
        "  # Criando listas vazias\n",
        "  data_rpi=[]\n",
        "  despacho1=[]\n",
        "  idpedido =[] \n",
        "  data=[]\n",
        "  original=[]\n",
        "  ipc=[]\n",
        "  titulo=[]\n",
        "  depositante=[]\n",
        "  ndata_rpi=''\n",
        " \n",
        "  i=0  # linha da lista que será extraída a informação\n",
        "  be=0\n",
        "  k=0\n",
        "  # Extração propriamente dita\n",
        "  for j in list1:\n",
        "        if list1[i][0:4]=='(21)' and k<(len(list1)-1) and (list1[i][list1[i].rindex(' ')+1:]=='1.3' or list1[i][list1[i].rindex(' ')+1:]=='3.1' or list1[i][list1[i].rindex(' ')+1:]=='3.2' or list1[i][list1[i].rindex(' ')+1:]=='2.4'):\n",
        "          be+=1 # contagem dos pedidos com despachos contidos em b\n",
        "          ndespacho1=''\n",
        "          npedido =''\n",
        "          ndata=''\n",
        "          noriginal=''\n",
        "          nipc=''\n",
        "          ntitulo=''\n",
        "          ndepositante=''\n",
        "\n",
        "          ndata_rpi=data_rpi1\n",
        "          npedido =j[5:17]\n",
        "          ndata=j[26:37] \n",
        "          ndespacho1=list1[i][list1[i].rindex(' ')+1:]\n",
        "        \n",
        "          # Este loop dentro do despacho é para verificar se o valor correto está sendo extraído\n",
        "          k=i+1\n",
        "          while list1[k][0:4] != '(21)':\n",
        "             if list1[k][0:4]=='(62)':\n",
        "               noriginal=list1[k][5:]\n",
        "             elif list1[k][0:4]=='(51)':\n",
        "               nipc=list1[k][5:]\n",
        "             elif list1[k][0:4]=='(54)':\n",
        "               ntitulo=list1[k][5:]\n",
        "             elif list1[k][0:4]=='(71)': \n",
        "               ndepositante=list1[k][5:]\n",
        "             k+=1\n",
        "             \n",
        "          # append as listas\n",
        "          data_rpi.append(ndata_rpi)\n",
        "          idpedido.append(npedido) \n",
        "          data.append(ndata)\n",
        "          original.append(noriginal) \n",
        "          ipc.append(nipc)\n",
        "          titulo.append(ntitulo)\n",
        "          depositante.append(ndepositante)\n",
        "          despacho1.append(ndespacho1)         \n",
        "\n",
        "\n",
        "        i+=1\n",
        "        \n",
        "  # Transformando as listas em dataframe   \n",
        "  pedido=pd.DataFrame(idpedido,columns=['idpedido'])\n",
        "  data=pd.DataFrame(data,columns=['data_deposito'])\n",
        "  original=pd.DataFrame(original,columns=['original'])\n",
        "  ipc=pd.DataFrame(ipc,columns=['ipc'])\n",
        "  titulo=pd.DataFrame(titulo,columns=['titulo'])\n",
        "  depositante=pd.DataFrame(depositante,columns=['depositante'])\n",
        "  despacho=pd.DataFrame(despacho1,columns=['despacho'])\n",
        "  data_rpi=pd.DataFrame(data_rpi,columns=['data_rpi'])\n",
        "\n",
        " \n",
        "  # Juntando os dataframes\n",
        "  frames=[pedido,data,original,ipc,titulo,depositante,despacho,data_rpi]\n",
        "  pedido=pd.concat(frames, axis=1)\n",
        "\n",
        "    \n",
        "  return pedido,be"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i2TyXsnbFKO"
      },
      "source": [
        "# Extraindo as informações e salvando-as em 2 dataframes\n",
        "data_rpi1='09/08/2011'\n",
        "data_rpi2='16/08/2011'\n",
        "df2118,a=restante(l2118,data_rpi1)\n",
        "df2119,a=restante(l2119,data_rpi2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2b0Pel4VkDG"
      },
      "source": [
        "df2118.sort_values(by=['ipc']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0B8sab7YBuj"
      },
      "source": [
        "df2118.sort_values(by=['ipc']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juI2asVMVlwJ"
      },
      "source": [
        "df2119.sort_values(by=['ipc']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORlfeoGAYQng"
      },
      "source": [
        "df2119.sort_values(by=['ipc']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4XVnnY3ZxMs"
      },
      "source": [
        "A extração dos despachos 1.3, 3.1, 3.2 e 2.4 foram extraídas com precisão dos arquivos pdf das RPI's 2118 e 2119.\n",
        "Vamos juntar os dois dataframes: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLSvpS_si6z3"
      },
      "source": [
        "fr=[df2118,df2119]\n",
        "dfrestante=pd.concat(fr)\n",
        "dfrestante.to_csv(\"dfrestante.csv\", index=False)\n",
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0LgOc6WnXeo"
      },
      "source": [
        "ped_pub=pd.read_csv('dep_pub_total.csv')\n",
        "ped_pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clzTBCjEqnxq"
      },
      "source": [
        "outros_total=pd.read_csv('outros_total.csv')\n",
        "outros_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uidhoY9jiNQS"
      },
      "source": [
        "nova_num_total=pd.read_csv('nova_num_total.csv')\n",
        "nova_num_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT8pIT-RnoX-"
      },
      "source": [
        "ped_pub.sort_values(by=['idpedido']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsAcKq-PUlTB"
      },
      "source": [
        "ped_pub.sort_values(by=['idpedido']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrcjvxVrUq80"
      },
      "source": [
        "ped_pub.sort_values(by=['data_deposito']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHBYhxNqrhCu"
      },
      "source": [
        "ped_pub.sort_values(by=['data_deposito']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgu5ZEuPrg_5"
      },
      "source": [
        "ped_pub.sort_values(by=['ipc']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D4ZsyTBrg9H"
      },
      "source": [
        "ped_pub.sort_values(by=['ipc']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFuS7Bd-rg6W"
      },
      "source": [
        "ped_pub.sort_values(by=['titulo']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WGkPpMntdae"
      },
      "source": [
        "ped_pub.sort_values(by=['titulo']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U_n6yO8tdXv"
      },
      "source": [
        "ped_pub.sort_values(by=['depositante']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu6i9ZFvtdVF"
      },
      "source": [
        "ped_pub.sort_values(by=['depositante']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOmuKXtkdtso"
      },
      "source": [
        "ped_pub['despacho'] = ped_pub['despacho'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhVNV_il0JO9"
      },
      "source": [
        "ped_pub.sort_values(by=['despacho']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsg_j6_HtdSc"
      },
      "source": [
        "ped_pub.sort_values(by=['despacho']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwE8beZY0akX"
      },
      "source": [
        "ped_pub.sort_values(by=['data_rpi']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6ICkOso0Dnt"
      },
      "source": [
        "ped_pub.sort_values(by=['data_rpi']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7SFLciS0Dy5"
      },
      "source": [
        "ped_pub.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHmABhVBRRQp"
      },
      "source": [
        "outros_total.sort_values(by=['idpedido']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr2YcwMBRzQv"
      },
      "source": [
        "outros_total.sort_values(by=['idpedido']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e8hdMnHRkJO"
      },
      "source": [
        "outros_total.sort_values(by=['despacho']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCr0ZlghSFbQ"
      },
      "source": [
        "outros_total.sort_values(by=['despacho']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aecA0z7nRqCH"
      },
      "source": [
        "outros_total.sort_values(by=['data_rpi']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru91wSr0SPcd"
      },
      "source": [
        "outros_total.sort_values(by=['data_rpi']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_ORAjxm0Duy"
      },
      "source": [
        "outros_total.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDkAI1qkl281"
      },
      "source": [
        "nova_num_total.sort_values(by=['idpedido']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOBRRkF2lzNa"
      },
      "source": [
        "nova_num_total.sort_values(by=['idpedido']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTeRr1C6mDl-"
      },
      "source": [
        "nova_num_total.sort_values(by=['novo_numero']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMmlSJeLmJPa"
      },
      "source": [
        "nova_num_total.sort_values(by=['novo_numero']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiQGTTA2nVmL"
      },
      "source": [
        "nova_num_total.sort_values(by=['data_rpi']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bizvKZOUnVxo"
      },
      "source": [
        "nova_num_total.sort_values(by=['data_rpi']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeWejUvnnh_C"
      },
      "source": [
        "nova_num_total.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk_u3F1cwtFQ"
      },
      "source": [
        "Pelas visualizações acima, verificamos que os dados foram extraídos de forma adequada. Vamos explorar mais os dtaframes nas etapas seguintes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEUTGzEEFKNA"
      },
      "source": [
        "Finalizamos a extração das informações, vamos à transformação dos dados!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7A8XjebFSOy"
      },
      "source": [
        "# **2.   Transformação**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zKecnbIJwfA"
      },
      "source": [
        "Pelas verificações acima, conclui-se que a etapa de transformação e limpeza dos dados faz-se necessária, devido à discrepância dos registros publicados nas RPI’s. Portanto, com base nas verificações feitas, algumas padronizações serão realizadas na etapa de transformação, tais como:\n",
        "\n",
        "1)\tTratar o dataframe nova_num_total no Excel, de forma deixar somente duas colunas (o número antigo e a nova numeração). Alguns ajustes terão que ser feitos manualmente, tendo em vista o fato de que a coluna novo_numero contém os comentários, os quais possuem o novo número do pedido. Algumas linhas foram excluídas, pois não tratavam de mudança de numeração ou era a renumeração de pedidos pipelines, que não serão estudados no presente trabalho. Este tratamento será feito no excel, dado que não há uma padronização nas alterações dos números dos pedidos, sendo que muitos passos terão que ser feitos manualmente;\n",
        "\n",
        "2)\tCriar uma nova coluna, que será a coluna chave, a qual será denominada de chave_idpedido. Nesta coluna serão removidas todas as strings, inclusive, após o traço “-“. A coluna idpedido será mantida;\n",
        "\n",
        "3)\tPadronizar as colunas da data de depósito e data da RPI nos dois dataframes, pois estas datas possuíam diversos formatos nas RPI’s: dd/mm/yyyy, dd/mm/yy ou ddmmyy. O formato padrão escolhido foi yyyy-mm-dd;\n",
        "\n",
        "4)\tCriar uma coluna contendo somente a primeira ipc do pedido no dataframe “ped_pub” (sem o ano de atualização da IPC, informação que consta nas revistas mais recentes, entre parênteses) para simplificação de análise, pois há pedidos que chegam a possuir mais de cinco classificações IPC;\n",
        "\n",
        "5)\tExcluir os caracteres especiais (#$&? etc.) dos títulos e passar todos os caracteres dos títulos para caixa alta no dataframe “ped_pub”;\n",
        "\n",
        "6)\tCriar uma coluna contendo somente o primeiro depositante e passando os caracteres para caixa alta nos dois dataframes;\n",
        "\n",
        "7)\tCriar mais três colunas subdividindo as classificações IPC: ipc_1 contém a seção da IPC (primeira letra da IPC), ipc_2 contém a subseção da ipc (três primeiros caracteres da IPC) e ipc_3 contém a classe da IPC (quatro primeiros caracteres da IPC) no dataframe “ped_pub”. Em suma, quanto maior a subdivisão, maior o detalhamento técnico informado pela IPC;\n",
        "\n",
        "8)\tCriar uma coluna informando o país de origem do depositante e outra contendo o estado, caso o país depositante seja o Brasil (BR);\n",
        "\n",
        "9)\tVerificar as repetições na coluna “idpedido” do dataframe “ped_pub”, e excluir as repetições mantendo-se o registro que contém a publicação na RPI mais recente;\n",
        "\n",
        "10)\tCriar uma nova coluna contendo a descrição da área e campo tecnológicos de acordo com a classificação IPC, segundo a OMPI – Organização Mundial da Propriedade Intelectual, utilizando o método merge;\n",
        "\n",
        "11)\tCriar uma nova coluna informando se o depositante é Residente (Brasil) ou Não-Residente (Internacional);\n",
        "\n",
        "12)\tPor fim, juntar os dois dataframes utilizando o método merge. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm8OeAU2hyuQ"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIwDtutVh5y7"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfQVKzMXavNs"
      },
      "source": [
        "ped_pub=pd.read_csv('dep_pub_total.csv')\n",
        "dfrestante=pd.read_csv('dfrestante.csv')\n",
        "outros=pd.read_csv(\"outros_total.csv\")\n",
        "nova_num_total_ed=pd.read_csv(\"nova_num_total_ed.csv\",encoding='iso-8859-1',delimiter=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yyc9Wp7gO-i"
      },
      "source": [
        "ped_pub['despacho'] = ped_pub['despacho'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ8J4wtMlRoD"
      },
      "source": [
        "dfrestante['despacho']=dfrestante['despacho'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjEHTefLnR7y"
      },
      "source": [
        "# Verificando o tipo de cada coluna n\n",
        "print(ped_pub.info())\n",
        "print(outros.info())\n",
        "print(nova_num_total_ed.info())\n",
        "print(dfrestante.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSEbnFHYErZw"
      },
      "source": [
        "Criando uma nova coluna chave_idpedido nos dataframes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-qtFuBEqGu"
      },
      "source": [
        "ped_pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzMTMcMFEq1s"
      },
      "source": [
        "outros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TlWPqH4ElkO"
      },
      "source": [
        "nova_num_total_ed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Gh-VAdFG4a"
      },
      "source": [
        "O dataframe nova_num_total_ed foi previamente trado no excel, vamos apenas renomear as colunas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNAx-_fpE5kj"
      },
      "source": [
        "nova_num_total_ed.columns = ['chave_idpedido', 'nova_chave_idpedido'] \n",
        "nova_num_total_ed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVozdlDzmNun"
      },
      "source": [
        "ped_pub['chave_idpedido'] = ped_pub['idpedido']\n",
        "outros['chave_idpedido'] = outros['idpedido']\n",
        "dfrestante['chave_idpedido']=dfrestante['idpedido']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZWvN-7dwKng"
      },
      "source": [
        "# Tirando os espaços no início e no fim de cada string da coluna chave_idpedido\n",
        "ped_pub['chave_idpedido'] = ped_pub['chave_idpedido'].str.lstrip()\n",
        "ped_pub['chave_idpedido'] = ped_pub['chave_idpedido'].str.rstrip()\n",
        "\n",
        "outros['chave_idpedido'] = outros['chave_idpedido'].str.lstrip()\n",
        "outros['chave_idpedido'] = outros['chave_idpedido'].str.rstrip()\n",
        "\n",
        "dfrestante['chave_idpedido']=dfrestante['chave_idpedido'].str.lstrip()\n",
        "dfrestante['chave_idpedido']=dfrestante['chave_idpedido'].str.rstrip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLTeczq7lanS"
      },
      "source": [
        "# Excluindo os kind codes da coluna chave_idpedido (consultar o site https://www.wipo.int/export/sites/www/standards/en/pdf/07-03-02.pdf para maiores informações)\n",
        "x=['A2','A8','B1','B8','C8','E2','E8','F1','F8','G8','U2','U8','Y1','Y8','Z8']\n",
        "for i in x:\n",
        "  ped_pub['chave_idpedido'] = ped_pub['chave_idpedido'].map(lambda x: x.replace(i,''))\n",
        "  outros['chave_idpedido'] = outros['chave_idpedido'].map(lambda x: x.replace(i,''))\n",
        "  nova_num_total_ed['chave_idpedido'] = nova_num_total_ed['chave_idpedido'].map(lambda x: x.replace(i,''))\n",
        "  nova_num_total_ed['nova_chave_idpedido'] = nova_num_total_ed['nova_chave_idpedido'].map(lambda x: x.replace(i,''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ea7FTPxwwaG"
      },
      "source": [
        "# Tirando os espaços no início e no fim de cada string da coluna chave_idpedido novamente\n",
        "ped_pub['chave_idpedido'] = ped_pub['chave_idpedido'].str.lstrip()\n",
        "ped_pub['chave_idpedido'] = ped_pub['chave_idpedido'].str.rstrip()\n",
        "\n",
        "outros['chave_idpedido'] = outros['chave_idpedido'].str.lstrip()\n",
        "outros['chave_idpedido'] = outros['chave_idpedido'].str.rstrip()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m0_j_HEmdg_"
      },
      "source": [
        "# Cada pedido de patente possui, antes do kind code, possuir um ifem seguindo de um número, que pode ser de 0 a 9. Vamos excluir estes números e o ifem também da chave_idpedido\n",
        "y=['-0','-1','-2','-3','-4','-5','-6','-7','-8','-9']\n",
        "for j in y:\n",
        "  ped_pub['chave_idpedido'] = ped_pub['chave_idpedido'].map(lambda x: x.replace(j,''))\n",
        "  outros['chave_idpedido'] = outros['chave_idpedido'].map(lambda x: x.replace(j,''))\n",
        "  dfrestante['chave_idpedido']=dfrestante['chave_idpedido'].map(lambda x: x.replace(j,''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF9WH-KInTiQ"
      },
      "source": [
        "# Removendo os espaços em todas as strings da coluna chave_idpedido\n",
        "ped_pub['chave_idpedido'] = ped_pub['chave_idpedido'].str.replace(' ', '')\n",
        "outros['chave_idpedido'] = outros['chave_idpedido'].str.replace(' ', '')\n",
        "nova_num_total_ed['chave_idpedido'] = nova_num_total_ed['chave_idpedido'].str.replace(' ', '')\n",
        "nova_num_total_ed['nova_chave_idpedido'] = nova_num_total_ed['nova_chave_idpedido'].str.replace(' ', '')\n",
        "dfrestante['chave_idpedido']=dfrestante['chave_idpedido'].str.replace(' ', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_-nKehjozsh"
      },
      "source": [
        "# Renomeando as colunas\n",
        "ped_pub=ped_pub[['chave_idpedido','idpedido','data_deposito', 'original','ipc','titulo','depositante','despacho','data_rpi']]\n",
        "outros=outros[['chave_idpedido','idpedido','data_deposito','depositante','despacho','data_rpi']]\n",
        "dfrestante=dfrestante[['chave_idpedido','idpedido','data_deposito', 'original','ipc','titulo','depositante','despacho','data_rpi']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqSEA5vxlvG5"
      },
      "source": [
        "ped_pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPl_85jzkFRo"
      },
      "source": [
        "outros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V51fGV1tJEK3"
      },
      "source": [
        "nova_num_total_ed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGRBbUmomrTX"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODE3OnPHpGIm"
      },
      "source": [
        "Adicionando uma nova coluna ao dataframe contendo apenas a primeira classificação:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVi3cvbEJUn7"
      },
      "source": [
        "# Função para pegar apenas a primeira classificação da coluna ipc\n",
        "def tira(test_str):\n",
        "    saida = ''\n",
        "    v1 = 0\n",
        "    v2 = 0\n",
        "    for i in str(test_str):\n",
        "        if i == ',':\n",
        "            v1 += 1\n",
        "        elif i == '(':\n",
        "            v2 += 1\n",
        "        elif i == ',' and v1 > 0:\n",
        "            v1 -= 1\n",
        "        elif i == ')'and v2 > 0:\n",
        "            v2 -= 1\n",
        "        elif v1 == 0 and v2 == 0:\n",
        "            saida += i\n",
        "    return saida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RAPoyjGsAFZ"
      },
      "source": [
        "# Extraindo somente a primeira classificação da coluna ipc, para criar a coluna ipc1\n",
        "ped_pub['ipc1'] = ped_pub['ipc'].apply(lambda x: tira(x))\n",
        "dfrestante['ipc1']=dfrestante['ipc'].apply(lambda x: tira(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SlRgworsPow"
      },
      "source": [
        "ped_pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEpGOzBPm_zd"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NquGsOfys88Q"
      },
      "source": [
        "Removendo os caracteres especiais da coluna titulo e aplicando a função upper em toda a coluna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOIWvrhYs8Hl"
      },
      "source": [
        "import re\n",
        "ped_pub['titulo1'] = ped_pub['titulo'].map(lambda x: re.sub(r'\\W+', ' ', str(x)))\n",
        "ped_pub['titulo1']=ped_pub['titulo1'].str.upper()\n",
        "dfrestante['titulo1'] = dfrestante['titulo'].map(lambda x: re.sub(r'\\W+', ' ', str(x)))\n",
        "dfrestante['titulo1']=dfrestante['titulo1'].str.upper()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYkpZHyykhnP"
      },
      "source": [
        "ped_pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8shxGWo_nSaB"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg8pZ0Njzqts"
      },
      "source": [
        "Modificando a função que foi aplicada às classificações, vamos criar uma coluna somente com o nome do 1º depositante e tudo em maiúsculo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbODgrKdZRXZ"
      },
      "source": [
        "# Função para pegar apenas o primeiro depositante com o país de origem\n",
        "def tira1(test_str):\n",
        "    saida = ''\n",
        "    v1 = 0\n",
        "    for i in str(test_str):\n",
        "        if i == ';':\n",
        "            v1 += 1\n",
        "        elif i == ';'  and v1>0:\n",
        "            v1 -= 1\n",
        "        elif v1 == 0:\n",
        "            saida += i\n",
        "    return saida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t__mChV0dPi"
      },
      "source": [
        "# Extraindo somente o primeiro depositante com o país de origem\n",
        "ped_pub['atalho'] = ped_pub['depositante'].apply(lambda x: tira1(x))\n",
        "ped_pub['atalho']=ped_pub['atalho'].str.upper()\n",
        "\n",
        "outros['atalho'] = outros['depositante'].apply(lambda x: tira1(x))\n",
        "outros['atalho']=outros['atalho'].str.upper()\n",
        "\n",
        "dfrestante['atalho'] = dfrestante['depositante'].apply(lambda x: tira1(x))\n",
        "dfrestante['atalho']=dfrestante['atalho'].str.upper()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMID1xJskoOL"
      },
      "source": [
        "ped_pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W47raUkcNu9c"
      },
      "source": [
        "outros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zobe2ViTnk4P"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI_WmF2UbFN7"
      },
      "source": [
        "Vamos pegar somente o depositante da coluna atalho e criar uma coluna depositante1 para armazenar estes dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByfKDAstbEeT"
      },
      "source": [
        "# Função para pegar apenas o primeiro depositante sem o país de origem\n",
        "def tira2(test_str):\n",
        "    saida = ''\n",
        "    v2 = 0\n",
        "    for i in str(test_str):\n",
        "        if i == '(':\n",
        "            v2 += 1\n",
        "        elif i == ')'and v2 > 0:\n",
        "            v2 -= 1\n",
        "        elif v2 == 0:\n",
        "            saida += i\n",
        "    return saida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxyV9b1pbEh2"
      },
      "source": [
        "# Extraindo somente o primeiro depositante sem o país de origem\n",
        "ped_pub['depositante1'] = ped_pub['atalho'].apply(lambda x: tira2(x))\n",
        "outros['depositante1'] = outros['atalho'].apply(lambda x: tira2(x))\n",
        "dfrestante['depositante1'] = dfrestante['atalho'].apply(lambda x: tira2(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s2x8mRpksUv"
      },
      "source": [
        "ped_pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97_7c3A8OD7S"
      },
      "source": [
        "outros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we5IeXCynzff"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqwfE0iFxmjv"
      },
      "source": [
        "Na coluna atalho podem exister alguns registros contendo outras strings entre parenteses, o que causa erro na extração do país do depositante. Vamos pegar então somente as 7 últimas posições da coluna atalho, para evitar que strings indesejadas sejam extraídas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFvfGyQlthn7"
      },
      "source": [
        "ped_pub['atalho2'] = ped_pub['atalho'].apply(lambda x: x[-7:])\n",
        "outros['atalho2'] = outros['atalho'].apply(lambda x: x[-7:])\n",
        "dfrestante['atalho2'] = dfrestante['atalho'].apply(lambda x: x[-7:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2hgsAvOkzPX"
      },
      "source": [
        "ped_pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-uu0GxrOPDc"
      },
      "source": [
        "outros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfWta8dRoBt9"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdu4D7XwAgQV"
      },
      "source": [
        "# Função para pegar apenas o país do depositante\n",
        "def tira3(test_str):\n",
        "    saida = ''\n",
        "    v2 = 0\n",
        "    for i in str(test_str):\n",
        "        if i == '(':\n",
        "            v2 += 1\n",
        "        elif i == ')'and v2 > 0:\n",
        "            v2 -= 1\n",
        "        elif v2 != 0:\n",
        "            saida += i\n",
        "    return saida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyQ2Tew8tzbv"
      },
      "source": [
        "ped_pub['atalho2'] = ped_pub['atalho2'].apply(lambda x: tira3(x))\n",
        "outros['atalho2'] = outros['atalho2'].apply(lambda x: tira3(x))\n",
        "dfrestante['atalho2'] = dfrestante['atalho2'].apply(lambda x: tira3(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISbu7dqBk4CX"
      },
      "source": [
        "ped_pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozJW7pq7OYVt"
      },
      "source": [
        "outros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGKxWub8oNr0"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TenfPIO-qg9u"
      },
      "source": [
        "dfrestante = dfrestante.reset_index(drop=True)\n",
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf9igVjBJgXR"
      },
      "source": [
        "# Extraindo somente o primeiro país e o estado, caso seja depositante nacional\n",
        "b=ped_pub['atalho2']\n",
        "origem_depos=[]\n",
        "origem_depos_estado=[]\n",
        "for i in b:\n",
        "  if len(i)==2:\n",
        "    nb=i\n",
        "    nb1=0\n",
        "  else:\n",
        "    nb=i[0:2]\n",
        "    if i[0:2]=='BR':\n",
        "      nb1=i[-2:]\n",
        "    elif i[0:2]!='BR':\n",
        "        nb1=0\n",
        "  origem_depos.append(nb)\n",
        "  origem_depos_estado.append(nb1)\n",
        "origem_depos=pd.DataFrame(origem_depos,columns=['ori_depos'])\n",
        "origem_depos_estado=pd.DataFrame(origem_depos_estado,columns=['ori_depos_est'])\n",
        "ped_pub['ori_depos']=origem_depos\n",
        "frames=[ped_pub,origem_depos_estado]\n",
        "ped_pub=pd.concat(frames, axis=1)\n",
        "\n",
        "\n",
        "b=outros['atalho2']\n",
        "origem_depos=[]\n",
        "origem_depos_estado=[]\n",
        "for i in b:\n",
        "  if len(i)==2:\n",
        "    nb=i\n",
        "    nb1=0\n",
        "  else:\n",
        "    nb=i[0:2]\n",
        "    if i[0:2]=='BR':\n",
        "      nb1=i[-2:]\n",
        "    elif i[0:2]!='BR':\n",
        "        nb1=0\n",
        "  origem_depos.append(nb)\n",
        "  origem_depos_estado.append(nb1)\n",
        "origem_depos=pd.DataFrame(origem_depos,columns=['ori_depos'])\n",
        "origem_depos_estado=pd.DataFrame(origem_depos_estado,columns=['ori_depos_est'])\n",
        "outros['ori_depos']=origem_depos\n",
        "frames=[outros,origem_depos_estado]\n",
        "outros=pd.concat(frames, axis=1)\n",
        "\n",
        "b=dfrestante['atalho2']\n",
        "origem_depos=[]\n",
        "origem_depos_estado=[]\n",
        "for i in b:\n",
        "  if len(i)==2:\n",
        "    nb=i\n",
        "    nb1=0\n",
        "  else:\n",
        "    nb=i[0:2]\n",
        "    if i[0:2]=='BR':\n",
        "      nb1=i[-2:]\n",
        "    elif i[0:2]!='BR':\n",
        "      nb1=0\n",
        "  origem_depos.append(nb)\n",
        "  origem_depos_estado.append(nb1)\n",
        "origem_depos=pd.DataFrame(origem_depos,columns=['ori_depos'])\n",
        "origem_depos_estado=pd.DataFrame(origem_depos_estado,columns=['ori_depos_est'])\n",
        "dfrestante['ori_depos']=origem_depos\n",
        "frames=[dfrestante,origem_depos_estado]\n",
        "dfrestante=pd.concat(frames, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X99FkrU2k8ZX"
      },
      "source": [
        "ped_pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbnWCDStSTWA"
      },
      "source": [
        "outros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lds-Oyil9id1"
      },
      "source": [
        "# Deletando as colunas atalho criadas\n",
        "del ped_pub['atalho']\n",
        "del ped_pub['atalho2']\n",
        "\n",
        "del outros['atalho']\n",
        "del outros['atalho2']\n",
        "\n",
        "del dfrestante['atalho']\n",
        "del dfrestante['atalho2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TrU_PKXlBBO"
      },
      "source": [
        "ped_pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIvbFClYSbDd"
      },
      "source": [
        "outros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGeIkgJUse0o"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD0pJObtkywc"
      },
      "source": [
        "Alterando as ordens da coluna e salvando em um novo dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jPnoHxlkUuS"
      },
      "source": [
        "ped_pub_final=ped_pub[['chave_idpedido','idpedido','data_deposito','original','ipc1','titulo1','depositante1','ori_depos','ori_depos_est','despacho','data_rpi']]\n",
        "outros_final=outros[['chave_idpedido','idpedido','data_deposito','depositante1','ori_depos','ori_depos_est','despacho','data_rpi']]\n",
        "dfrestante=dfrestante[['chave_idpedido','idpedido','data_deposito','original','ipc1','titulo1','depositante1','ori_depos','ori_depos_est','despacho','data_rpi']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKplMWUKpZ87"
      },
      "source": [
        "ped_pub_final.sort_values(by=['idpedido']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4uaTaN9TON4"
      },
      "source": [
        "outros_final.sort_values(by=['idpedido']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhKa-CccmrqR"
      },
      "source": [
        "ped_pub_final.sort_values(by=['idpedido']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQGblUE1TcPB"
      },
      "source": [
        "outros_final.sort_values(by=['idpedido']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZablUUrPmry1"
      },
      "source": [
        "ped_pub_final.sort_values(by=['data_deposito']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZRUI8cQv1qY"
      },
      "source": [
        "ped_pub_final.sort_values(by=['data_deposito']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8jee2crUKhF"
      },
      "source": [
        "outros_final.sort_values(by=['data_deposito']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrGKmHzAn5U9"
      },
      "source": [
        "ped_pub_final.sort_values(by=['data_deposito']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI3t1uEgUZFx"
      },
      "source": [
        "outros_final.sort_values(by=['data_deposito']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUc7M9IFiDQH"
      },
      "source": [
        "ped_pub_final.sort_values(by=['data_rpi']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "016D0SybaCgN"
      },
      "source": [
        "outros_final.sort_values(by=['despacho']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIb7WRfOaHAZ"
      },
      "source": [
        "outros_final.sort_values(by=['despacho']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6E_QU1ZVDQF"
      },
      "source": [
        "outros_final.sort_values(by=['data_rpi']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jacPSp1khzfk"
      },
      "source": [
        "ped_pub_final.sort_values(by=['data_rpi']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6ML2EpjVK4W"
      },
      "source": [
        "outros_final.sort_values(by=['data_rpi']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzqliazVqCm0"
      },
      "source": [
        "Renumerando o index do dataframe para ficar em ordem:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XskuN-dkqBVG"
      },
      "source": [
        "ped_pub_final = ped_pub_final.reset_index(drop=True)\n",
        "outros_final = outros_final.reset_index(drop=True)\n",
        "dfrestante = dfrestante.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4YSV3kxCo91"
      },
      "source": [
        "ped_pub_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV7pkdxEXEHH"
      },
      "source": [
        "outros_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHUUshBftENU"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hGheD6CzKai"
      },
      "source": [
        "Vamos eliminar as barras de todas as datas para poder padronizar um formato único:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXNxMoZC3CyW"
      },
      "source": [
        "ped_pub_final['data_deposito1'] = ped_pub_final['data_deposito'].apply(lambda x: str(x).replace('/',''))\n",
        "ped_pub_final['data_rpi1'] = ped_pub_final['data_rpi'].apply(lambda x: str(x).replace('/',''))\n",
        "\n",
        "outros_final['data_deposito1'] = outros['data_deposito'].apply(lambda x: str(x).replace('/',''))\n",
        "outros_final['data_rpi1'] = outros['data_rpi'].apply(lambda x: str(x).replace('/',''))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRgTRyQJ3KYE"
      },
      "source": [
        "ped_pub_final.sort_values(by=['data_deposito1']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mQyyhba5qXn"
      },
      "source": [
        "ped_pub_final.sort_values(by=['data_deposito1']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBXSqOop7TuM"
      },
      "source": [
        "outros_final.sort_values(by=['data_deposito1']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd89Sk7z446p"
      },
      "source": [
        "outros_final.sort_values(by=['data_deposito1']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JW4KHAL4Ep0"
      },
      "source": [
        "# Removendo os espaços das strings das colunas que contém data\n",
        "dfrestante['data_rpi'] = dfrestante['data_rpi'].apply(lambda x: str(x).replace(' ',''))\n",
        "dfrestante['data_deposito']= dfrestante['data_deposito'].apply(lambda x: str(x).replace(' ',''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ok7QPkWHyfX"
      },
      "source": [
        "# Função para transformar a data no formato data do python:\n",
        "from datetime import datetime\n",
        "def data_f(coluna):\n",
        "  data=[]\n",
        "  ndata=''\n",
        "  lista=[]\n",
        "  for i in coluna:\n",
        "    if len(str(i))==8:\n",
        "      y=str(i[-4:])\n",
        "      m=str(i[2:4])\n",
        "      d=str(i[0:2])\n",
        "      z=y+'-'+m+'-'+d\n",
        "    elif len(str(i))==6:\n",
        "      y='19'+str(i[-2:])\n",
        "      m=str(i[2:4])\n",
        "      d=str(i[0:2])\n",
        "      if m.isnumeric()==False:\n",
        "        m='10'\n",
        "      elif d.isnumeric()==False:\n",
        "        d='10'\n",
        "      z=y+'-'+m+'-'+d\n",
        "    elif len(str(i))<6 :\n",
        "      z='1991-01-01'\n",
        "    lista.append(z)\n",
        "\n",
        "  for i in lista:\n",
        "    try:\n",
        "      ndata = datetime.strptime(i, '%Y-%m-%d').date()\n",
        "    except:\n",
        "      ndata = datetime.strptime('1991-01-01', '%Y-%m-%d').date()\n",
        "    data.append(ndata)\n",
        "  data=pd.DataFrame(data,columns=['data_'])\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmZBbaPT0sO3"
      },
      "source": [
        "# Função para transformar a data no formato data do python:\n",
        "from datetime import datetime\n",
        "def data_r(coluna):\n",
        "  data=[]\n",
        "  ndata=''\n",
        "  lista=[]\n",
        "  for i in coluna:\n",
        "    if len(str(i))==10:\n",
        "      y=str(i[-4:])\n",
        "      m=str(i[3:5])\n",
        "      d=str(i[0:2])\n",
        "      z=y+'-'+m+'-'+d\n",
        "    lista.append(z)\n",
        "  for i in lista:\n",
        "    ndata = datetime.strptime(i, '%Y-%m-%d').date()\n",
        "    data.append(ndata)\n",
        "  data=pd.DataFrame(data,columns=['data_'])\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB-SHE4A-txV"
      },
      "source": [
        "# aplicando as funções\n",
        "ped_pub_final['data_deposito2']=data_f(ped_pub_final['data_deposito1'])\n",
        "ped_pub_final['data_rpi2']=data_f(ped_pub_final['data_rpi1'])\n",
        "\n",
        "outros_final['data_deposito2']=data_f(outros_final['data_deposito1'])\n",
        "outros_final['data_rpi2']=data_f(outros_final['data_rpi1'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVfIS5apuvrQ"
      },
      "source": [
        "dfrestante['data_deposito1']=data_r(dfrestante['data_deposito'])\n",
        "dfrestante['data_rpi1']=data_r(dfrestante['data_rpi'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9O8lVwjc1EU"
      },
      "source": [
        "ped_pub_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDxqBoE7u_o7"
      },
      "source": [
        "outros_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "milShd7nxM1u"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNk8ACJ-JhVL"
      },
      "source": [
        "outros_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDZGc7nmmQRm"
      },
      "source": [
        "ped_pub_final=ped_pub_final[['chave_idpedido','idpedido','data_deposito2','original','ipc1','titulo1','depositante1','ori_depos','ori_depos_est','despacho','data_rpi2']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6C9ffOM6jkA"
      },
      "source": [
        "dfrestante=dfrestante[['chave_idpedido','idpedido','data_deposito1','original','ipc1','titulo1','depositante1','ori_depos','ori_depos_est','despacho','data_rpi1']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QJQnJVbX3W7"
      },
      "source": [
        "outros_f=outros_final[['chave_idpedido','idpedido','data_deposito2','depositante1','ori_depos','ori_depos_est','despacho','data_rpi2']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-VCaYQtaCcb"
      },
      "source": [
        "ped_pub_final.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0v0sjUQgLyN"
      },
      "source": [
        "outros_f.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qNGHH0OLs3b"
      },
      "source": [
        "outros_f['despacho'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNwck8e-L7FI"
      },
      "source": [
        "outros_f.columns = ['chave_idpedido','idpedido','data_deposito','depositante','ori_depos','ori_depos_est','despacho','data_rpi']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuD6e15bNJ8Q"
      },
      "source": [
        "outros_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2lkjHDJ8VCO"
      },
      "source": [
        "import numpy as np\n",
        "np.size(outros_f['depositante'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE5WkTmm8h7K"
      },
      "source": [
        "np.size(outros_f['ori_depos'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFG9eidgoAs1"
      },
      "source": [
        "# Função para tirar as vírgulas dos depositantes\n",
        "def tira4(test_str):\n",
        "    saida = ''\n",
        "    v1 = 0\n",
        "    for i in str(test_str):\n",
        "        if i == ',':\n",
        "            v1 += 1\n",
        "        elif i == ','  and v1>0:\n",
        "            v1 -= 1\n",
        "        elif v1 == 0:\n",
        "            saida += i\n",
        "    return saida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2tSrSx0oA7B"
      },
      "source": [
        "outros_f['depositante2'] = outros_f['depositante'].apply(lambda x: tira4(x))\n",
        "outros_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2XKizhK8sFr"
      },
      "source": [
        "Removendo os caracteres especiais dos depositantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2He43mJ0LHx"
      },
      "source": [
        "import re\n",
        "outros_f['depositante2'] = outros_f['depositante2'].map(lambda x: re.sub(r'\\W+', ' ', str(x)))\n",
        "outros_f['depositante2']=outros_f['depositante2'].str.upper()\n",
        "outros_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBqQ0Ge15W5C"
      },
      "source": [
        "Removendo a acentuação dos depositantes, para evitar diferenças:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CS2Dw6u4OZY"
      },
      "source": [
        "import numpy as np\n",
        "outros_f['depositante2']=outros_f['depositante2'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "outros_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GlCEj1E58Zn"
      },
      "source": [
        "del outros_f['depositante']\n",
        "outros_f=outros_f[['chave_idpedido','idpedido','data_deposito','depositante2','ori_depos','ori_depos_est','despacho','data_rpi']]\n",
        "outros_f.columns = ['chave_idpedido','idpedido','data_deposito','depositante','ori_depos','ori_depos_est','despacho','data_rpi']\n",
        "outros_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr1JWOKv58l_"
      },
      "source": [
        "np.size(outros_f['depositante'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkSe5xWvNcKm"
      },
      "source": [
        "# salvando como arquivo csv para trabalhar no arquivo posteriormente:\n",
        "outros_f.to_csv(\"outros_f.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXlxdVcFSKep"
      },
      "source": [
        "Voltando para o dataframe ped_pub_final e dfrestante:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6okYcT37WvV8"
      },
      "source": [
        "ped_pub_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_McdHkz868vp"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmCjH7c8--_F"
      },
      "source": [
        "ped_pub_final.sort_values(by=['data_deposito2']).head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cEfsf9K_LqQ"
      },
      "source": [
        "ped_pub_final.sort_values(by=['data_deposito2']).tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKSRqHPzoM17"
      },
      "source": [
        "Vamos separar as classificações em três níveis. O primeiro nível, é só a primeira letra da classificação i[0:1], o segundo nível trata dos 3 primeiros digitos da classificação i[0:3] e o terceiro nível de detalhe são os 4 primeiros dígitos i[0:4]. Lembrando que cada nível apresenta um detalhamento maior da tecnologia a que se refere aquela classificação:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFqN71JvyiCu"
      },
      "source": [
        "ped_pub_final['ipc1_1'] = ped_pub_final['ipc1'].apply(lambda x: x[0:1])\n",
        "dfrestante['ipc1_1'] = dfrestante['ipc1'].apply(lambda x: x[0:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVoJqag9m4HR"
      },
      "source": [
        "ped_pub_final['ipc1_2'] = ped_pub_final['ipc1'].apply(lambda x: x[0:3])\n",
        "dfrestante['ipc1_2'] = dfrestante['ipc1'].apply(lambda x: x[0:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zdNUnXrm59D"
      },
      "source": [
        "ped_pub_final['ipc1_3'] = ped_pub_final['ipc1'].apply(lambda x: x[0:4])\n",
        "dfrestante['ipc1_3'] = dfrestante['ipc1'].apply(lambda x: x[0:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1oReoTsqero"
      },
      "source": [
        "ped_pub_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu0Pa6wJ7ZE6"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2g9aWdIt_9M"
      },
      "source": [
        "Removendo algumas repetições que ocorrem em algumas linhas da coluna depositante1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCKhuk4auJnq"
      },
      "source": [
        "def tira4(test_str):\n",
        "    saida = ''\n",
        "    v1 = 0\n",
        "    for i in str(test_str):\n",
        "        if i == ',':\n",
        "            v1 += 1\n",
        "        elif i == ','  and v1>0:\n",
        "            v1 -= 1\n",
        "        elif v1 == 0:\n",
        "            saida += i\n",
        "    return saida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW65VhtxuJrE"
      },
      "source": [
        "ped_pub_final['depositante2'] = ped_pub_final['depositante1'].apply(lambda x: tira4(x))\n",
        "dfrestante['depositante2'] = dfrestante['depositante1'].apply(lambda x: tira4(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GUp4C2suJuv"
      },
      "source": [
        "ped_pub_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5MXQ2mC7lwQ"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kquceqQHBiDk"
      },
      "source": [
        "import re\n",
        "ped_pub_final['depositante3'] = ped_pub_final['depositante2'].map(lambda x: re.sub(r'\\W+', ' ', str(x)))\n",
        "ped_pub_final['depositante3']=ped_pub_final['depositante3'].str.upper()\n",
        "\n",
        "dfrestante['depositante3'] = dfrestante['depositante2'].map(lambda x: re.sub(r'\\W+', ' ', str(x)))\n",
        "dfrestante['depositante3']=dfrestante['depositante3'].str.upper()\n",
        "ped_pub_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsFZp9VC7z9Y"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6wTJJyqDLR4"
      },
      "source": [
        "import numpy as np\n",
        "ped_pub_final['depositante4']=ped_pub_final['depositante3'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "dfrestante['depositante4']=dfrestante['depositante3'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "ped_pub_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLjMWHyx7-VV"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs4LsRkhDo3Z"
      },
      "source": [
        "ped_pub_final['titulo2']=ped_pub_final['titulo1'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "dfrestante['titulo2']=dfrestante['titulo1'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "ped_pub_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOF7JEfo8Lbq"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF_r-QKcBA9x"
      },
      "source": [
        "ped_pub_f=ped_pub_final[['chave_idpedido','idpedido','data_deposito2','original','ipc1','ipc1_1','ipc1_2','ipc1_3','titulo2','depositante4','ori_depos','ori_depos_est','despacho','data_rpi2']]\n",
        "ped_pub_f.columns = ['chave_idpedido','idpedido','data_deposito','original','ipc','ipc_1','ipc_2','ipc_3','titulo','depositante','ori_depos','ori_depos_est','despacho','data_rpi']\n",
        "dfrestante=dfrestante[['chave_idpedido','idpedido','data_deposito1','original','ipc1','ipc1_1','ipc1_2','ipc1_3','titulo2','depositante4','ori_depos','ori_depos_est','despacho','data_rpi1']]\n",
        "dfrestante.columns = ['chave_idpedido','idpedido','data_deposito','original','ipc','ipc_1','ipc_2','ipc_3','titulo','depositante','ori_depos','ori_depos_est','despacho','data_rpi']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsfu_a31BBBJ"
      },
      "source": [
        "ped_pub_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZaCpHl08n9I"
      },
      "source": [
        "dfrestante"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyeXlUSnEVGM"
      },
      "source": [
        "Verificando se há idpedidos repetidos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFwEGQv2BBGO"
      },
      "source": [
        "dupl=ped_pub_f['chave_idpedido'].value_counts().rename_axis('unique_values').to_frame('counts')\n",
        "dupl2=dfrestante['chave_idpedido'].value_counts().rename_axis('unique_values').to_frame('counts')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc7Y8YPXBA6x"
      },
      "source": [
        "dupl.head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekQqK1ei95Eu"
      },
      "source": [
        "dupl2.head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1raK4XGeo690"
      },
      "source": [
        "print(ped_pub_f['ori_depos'].value_counts().rename_axis('unique_values').to_frame('counts').to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Aem-2Ept5l"
      },
      "source": [
        "ped_pub_f['depositante'].value_counts().rename_axis('unique_values').to_frame('counts').head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5JBIm4RqASl"
      },
      "source": [
        "ped_pub_f['depositante'].value_counts().rename_axis('unique_values').to_frame('counts').tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL7zPYcnEoR4"
      },
      "source": [
        "ped_pub_f.loc[ped_pub_f['chave_idpedido'] == 'BR112014000556']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nByzK9hhgU6j"
      },
      "source": [
        "ped_pub_f.loc[ped_pub_f['chave_idpedido'] == 'BR112014025730']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO4hDdjBh_Hq"
      },
      "source": [
        "ped_pub_f.loc[ped_pub_f['chave_idpedido'] == 'BR112015014844']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwCiUCpxihzi"
      },
      "source": [
        "Como observado acima, podem haver simples repetições da publicação do pedido por causa da anulação da publicação anterior ou qualquer outro motivo para correção de outras informações. Assim, manteremos o registro com a última publicação na rpi, removendo os registros anteriores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mmlc67azc6t"
      },
      "source": [
        "ped_pub_f=ped_pub_f.sort_values(by=['chave_idpedido','data_rpi'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jj4V1UZejhj"
      },
      "source": [
        "ped_pub_f = ped_pub_f.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6SNC7UyVPhH"
      },
      "source": [
        "ped_pub_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gb7f1SjerVW"
      },
      "source": [
        "ped_pub_f.loc[ped_pub_f['chave_idpedido'] == 'BR102017020904']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq6ayrMlerhL"
      },
      "source": [
        "ped_pub_f.loc[ped_pub_f['chave_idpedido'] == 'BR112014000976']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkL2y-z2VPpN"
      },
      "source": [
        "ped_pub_f.loc[ped_pub_f['chave_idpedido'] == 'BR112015014844']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bofVKargjVB7"
      },
      "source": [
        "Eliminando, então, as linhas com idpedido repetidas, mantendo o último idpedido (data mais recente da rpi):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y_lzL6yjk_g"
      },
      "source": [
        "ped_pub_f=ped_pub_f.drop_duplicates(subset='chave_idpedido', keep=\"last\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF6O2BZPj01b"
      },
      "source": [
        "ped_pub_f['chave_idpedido'].value_counts().rename_axis('unique_values').to_frame('counts')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYhkxxkxkDOb"
      },
      "source": [
        "Agora todas as idpedido repetidas foram removidas, mantendo-se apenas as que foram publicadas na rpi mais recente!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ALUDWbcJ3u2"
      },
      "source": [
        "ped_pub_f=ped_pub_f.sort_values(by=['data_deposito'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UApWvKv5kQmf"
      },
      "source": [
        "ped_pub_f = ped_pub_f.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLLEZiiTkSxx"
      },
      "source": [
        "ped_pub_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0PtrzMyED3s"
      },
      "source": [
        "ped_pub_f.to_csv(\"ped_pub_f.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udBqyHU8-F_n"
      },
      "source": [
        "dfrestante.to_csv('dfrestante_f.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlLYQ2qttc9G"
      },
      "source": [
        "Vamos criar novas colunas descrevendo as tecnologias a que cada ipc representa de acordo com as definições da OMPI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKAy4K6xo-hE"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdFhY8lJmTls"
      },
      "source": [
        "ped_pub_f=pd.read_csv(\"ped_pub_f.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QLasVXb-wQC"
      },
      "source": [
        "dfrestante_f=pd.read_csv('dfrestante_f.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xihTtFTupbWM"
      },
      "source": [
        "area_campo_ompi=pd.read_csv('area_campo_ompi.csv',encoding='iso-8859-1',delimiter=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Asr3b_hpbG5"
      },
      "source": [
        "area_campo_ompi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvaNN7WKQEcZ"
      },
      "source": [
        "ped_pub_f=ped_pub_f.sort_values(by=['ipc'])\n",
        "ped_pub_f = ped_pub_f.reset_index(drop=True)\n",
        "\n",
        "dfrestante_f=dfrestante_f.sort_values(by=['ipc'])\n",
        "dfrestante_f = dfrestante_f.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTD_dg-gQOxN"
      },
      "source": [
        "ped_pub_f.head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A_6R_6Jtdd2"
      },
      "source": [
        "ped_pub_f.tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTfDFXhE_ILA"
      },
      "source": [
        "dfrestante_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySwStyksA91-"
      },
      "source": [
        "verif=ped_pub_f.loc[ped_pub_f['ipc'].isna() == True].sort_values(by=['data_deposito'])\n",
        "verif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqN1TVi0zj6B"
      },
      "source": [
        "verif.loc[verif['data_deposito'] < '1993-01-01']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA7IizHv0_-B"
      },
      "source": [
        "verif.loc[verif['data_deposito'] > '2018-12-31']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaX8fUWTl1Ze"
      },
      "source": [
        "Removendo os espaços entre as classificações:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTYquzJR-Rnh"
      },
      "source": [
        "ped_pub_f['ipc'] = ped_pub_f['ipc'].str.replace(' ', '')\n",
        "dfrestante_f['ipc'] = dfrestante_f['ipc'].str.replace(' ', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyD0AKDl9vtr"
      },
      "source": [
        "ped_pub_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRcxqecH_ZEq"
      },
      "source": [
        "dfrestante_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p28dytM6qkH8"
      },
      "source": [
        "Inserindo uma nova coluna no df para utilizar as definições tecnologicas de arcodo com a OMPI:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djt-LvusPY5h"
      },
      "source": [
        "at=[]\n",
        "n=''\n",
        "for i in ped_pub_f['ipc']:\n",
        "  i=str(i)\n",
        "  if i[0:4]=='A61K':\n",
        "    if i[0:6]=='A61K8/':\n",
        "      n=i[0:6]\n",
        "    else:\n",
        "      n=i[0:4]\n",
        "  elif i[0:4]=='B01D':\n",
        "    if i[0:7]=='B01D45/' or i[0:7]=='B01D46/' or i[0:7]=='B01D47/' or i[0:7]=='B01D49/' or i[0:7]=='B01D50/' or i[0:7]=='B01D51/' or i[0:7]=='B01D52/':\n",
        "      n=i[0:7]\n",
        "    else:\n",
        "        n=i[0:4]\n",
        "  elif i[0:4]=='C13B':\n",
        "    if i[0:6]=='C13B5/':\n",
        "      n=i[0:6]\n",
        "    elif i[0:7]=='C13B15/'  or i[0:7]=='C13B25/'  or i[0:7]=='C13B45/':\n",
        "      n=i[0:7]\n",
        "    else:\n",
        "      n=i[0:4]\n",
        "  elif i[0:4]=='E01F':\n",
        "    if i[0:6]=='E01F8/':\n",
        "      n=i[0:6]\n",
        "    else:\n",
        "      n=i[0:4]\n",
        "  elif i[0:4]=='G01N':\n",
        "    if i[0:7]=='G01N33/':\n",
        "      n=i[0:7]\n",
        "    else:\n",
        "      n=i[0:4]\n",
        "  elif i[0:4]=='H04N':\n",
        "    if i[0:6]=='H04N1/':\n",
        "      n=i[0:6]\n",
        "    elif i[0:7]=='H04N21/':\n",
        "      n=i[0:7]\n",
        "    else:\n",
        "      n=i[0:4]    \n",
        "  else:\n",
        "    n=i[0:4]\n",
        "  at.append(n)\n",
        "ipc_at=pd.DataFrame(at,columns=['ipc_at'])\n",
        "ped_pub_f['ipc_at']=ipc_at"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTD_T2Em_gw5"
      },
      "source": [
        "at=[]\n",
        "n=''\n",
        "for i in dfrestante_f['ipc']:\n",
        "  i=str(i)\n",
        "  if i[0:4]=='A61K':\n",
        "    if i[0:6]=='A61K8/':\n",
        "      n=i[0:6]\n",
        "    else:\n",
        "      n=i[0:4]\n",
        "  elif i[0:4]=='B01D':\n",
        "    if i[0:7]=='B01D45/' or i[0:7]=='B01D46/' or i[0:7]=='B01D47/' or i[0:7]=='B01D49/' or i[0:7]=='B01D50/' or i[0:7]=='B01D51/' or i[0:7]=='B01D52/':\n",
        "      n=i[0:7]\n",
        "    else:\n",
        "        n=i[0:4]\n",
        "  elif i[0:4]=='C13B':\n",
        "    if i[0:6]=='C13B5/':\n",
        "      n=i[0:6]\n",
        "    elif i[0:7]=='C13B15/'  or i[0:7]=='C13B25/'  or i[0:7]=='C13B45/':\n",
        "      n=i[0:7]\n",
        "    else:\n",
        "      n=i[0:4]\n",
        "  elif i[0:4]=='E01F':\n",
        "    if i[0:6]=='E01F8/':\n",
        "      n=i[0:6]\n",
        "    else:\n",
        "      n=i[0:4]\n",
        "  elif i[0:4]=='G01N':\n",
        "    if i[0:7]=='G01N33/':\n",
        "      n=i[0:7]\n",
        "    else:\n",
        "      n=i[0:4]\n",
        "  elif i[0:4]=='H04N':\n",
        "    if i[0:6]=='H04N1/':\n",
        "      n=i[0:6]\n",
        "    elif i[0:7]=='H04N21/':\n",
        "      n=i[0:7]\n",
        "    else:\n",
        "      n=i[0:4]    \n",
        "  else:\n",
        "    n=i[0:4]\n",
        "  at.append(n)\n",
        "ipc_at=pd.DataFrame(at,columns=['ipc_at'])\n",
        "dfrestante_f['ipc_at']=ipc_at"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtOTDAiTPY-j"
      },
      "source": [
        "ped_pub_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnNyivrs_thl"
      },
      "source": [
        "dfrestante_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkeftnOtfXpk"
      },
      "source": [
        "Aplicando o método merge nos dois df, teremos uma nova coluna informando a área e o campo tecnológico de acordo com a tabela area_campo_ompi:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF3g6kQOvEzp"
      },
      "source": [
        "result = pd.merge(ped_pub_f,area_campo_ompi, how='outer')\n",
        "rdfrestante_f = pd.merge(dfrestante_f,area_campo_ompi, how='outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfB78F5HPR_w"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NboXjfwF_8aV"
      },
      "source": [
        "rdfrestante_f.head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls7cjVGdAHOz"
      },
      "source": [
        "rdfrestante_f.tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVOP8Yv3Fb7N"
      },
      "source": [
        "result.head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHSmrEIM2t9P"
      },
      "source": [
        "result.tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMH7mSI42LzD"
      },
      "source": [
        "Vamos guardar as linhas com NaN do df acima, talvez possa ser útil mais adiante. Depois vamos deletar estas linhas>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkrudTxB1ANs"
      },
      "source": [
        "nan_result=result[619157:]\n",
        "nan_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ehd6hQXGhNv"
      },
      "source": [
        "nan_result.to_csv(\"nan_result.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeH4aiGXgio0"
      },
      "source": [
        "result = result.drop(result[619157:].index)\n",
        "result.tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRtmX-WzAWHa"
      },
      "source": [
        "rdfrestante_f = rdfrestante_f.drop(rdfrestante_f[979:].index)\n",
        "rdfrestante_f.tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flozpWkzWJIp"
      },
      "source": [
        "Podemos criar mais uma coluna, informando se o depositante é de origem internacional (Não-Residente) ou nacional (Residente):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69DpOYdCV6pk"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePDLgmaRXHu-"
      },
      "source": [
        "def nac_int(x):\n",
        "  if x=='BR':\n",
        "    y='residente'\n",
        "  else:\n",
        "    y='nao_residente'\n",
        "  return (y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no2_QX5pV6mZ"
      },
      "source": [
        "result['Nac_Inter']=result['ori_depos'].apply(lambda x: nac_int(x))\n",
        "rdfrestante_f['Nac_Inter']=rdfrestante_f['ori_depos'].apply(lambda x: nac_int(x))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq8edqgsA_zE"
      },
      "source": [
        "rdfrestante_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDlcoQlAja7H"
      },
      "source": [
        "result['Nac_Inter'].value_counts().rename_axis('unique_values').to_frame('counts')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9COd4qZVs5HT"
      },
      "source": [
        "result['area_campo_ompi'].value_counts().rename_axis('unique_values').to_frame('counts')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6rShlCBPbhv"
      },
      "source": [
        "result=result.sort_values(by=['data_deposito'])\n",
        "result = result.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBKPjC2WtJ8a"
      },
      "source": [
        "result.head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arsBVeRvtYFH"
      },
      "source": [
        "result.tail(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5rnfNnLvPW0"
      },
      "source": [
        "result.loc[result['data_deposito'] < '1993-01-01']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHDT1Gae5EBj"
      },
      "source": [
        "#result = result.drop(result[0:12455].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZyBwRFg6Kx8"
      },
      "source": [
        "result = result.reset_index(drop=True)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHxC_tIK5ELM"
      },
      "source": [
        "result.loc[result['data_deposito'] >'2020-12-31']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROUdAPpYtIZM"
      },
      "source": [
        "result.to_csv(\"result_f.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8kEmg9qBIXQ"
      },
      "source": [
        "rdfrestante_f.to_csv(\"rdfrestante_f_f.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0L8vqAkBaRP"
      },
      "source": [
        "rdfrestante_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFJVK392zGsX"
      },
      "source": [
        "outros_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ-05cgb5b0q"
      },
      "source": [
        "outros_f['despacho'].value_counts().rename_axis('unique_values').to_frame('counts')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGmWUoAT4JVn"
      },
      "source": [
        "Cada despacho significa:\n",
        "\n",
        "11.1.1 - Arquivamento - Art. 33 Parágravo único da LPI\n",
        "\n",
        "11.11 - Arquivamento - Art.17§ 2º da LPI\n",
        "\n",
        "11.18 - Arquivamento definitivo por não anuência relacionada com o Art. 229-C da LPI.\n",
        "\n",
        "11.2 - Arquivamento definitivo - Art. 36 §1° da LPI\n",
        "\n",
        "11.4 - Arquivamento - Art.38 § 2º da LPI\n",
        "\n",
        "11.5 - Arquivamento - Art.34 da LPI\n",
        "\n",
        "11.6 - Arquivamento do Pedido - Art.216 § 2º da LPI\n",
        "\n",
        "11.30 - Arquivamento Definitivo - Art. 18 § 1º da Lei 5772/71\n",
        "\n",
        "11.31 - Arquivamento Definitivo - Falta de Cumprimento de exigência\n",
        "\n",
        "11.6 - Arquivamento do Pedido - Art.216 § 2º da LPI\n",
        "\n",
        "6.1 - Exigência - Art.36 da LPI\n",
        "\n",
        "6.20 - Exigência Pré-Exame - Art. 34 da LPI\n",
        "\n",
        "6.21 - Exigência preliminar - pedidos com buscas realizadas por outros Escritórios de Patentes\n",
        "\n",
        "6.22 - Exigência preliminar - pedidos sem buscas realizadas por outros Escritórios de Patentes\n",
        "\n",
        "7.1 - Conhecimento do Parecer Técnico\n",
        "\n",
        "8.6 - Arquivamento - Art.86 da LPI\n",
        "\n",
        "8.11 - Manutenção do Arquivamento\n",
        "\n",
        "8.12 - Arquivamento Definitivo\n",
        "\n",
        "9.1 - Deferimento\n",
        "\n",
        "9.2 - Indeferimento\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgpvIVr_jsBw"
      },
      "source": [
        "outros_f.to_csv(\"outros_f.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOVKJnQH1o4p"
      },
      "source": [
        "# Removendo os espaços das colunas\n",
        "nova_num_total_ed.columns = ['chave_original', 'chave_idpedido'] \n",
        "nova_num_total_ed['chave_original'] = nova_num_total_ed['chave_original'].str.replace(' ', '')\n",
        "nova_num_total_ed['chave_idpedido'] = nova_num_total_ed['chave_idpedido'].str.replace(' ', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA_kAkTkU3Mz"
      },
      "source": [
        "nova_num_total_ed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaK-eZZ3gunS"
      },
      "source": [
        "Após as transformações acima, juntamos os pedidos restantes das RPI's 2118 e 2119 ao dataframe com as outras publicações. As verificações de duplicidade e verificação dos pedidos com renumeração foram feitas no excel, pelo método procv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYnTgw4Xcnq2"
      },
      "source": [
        "Primeiro, antes de fazer o merge, tivemos que preparar os arquivos para fazer o merge de forma correta. Dividimos o arquivo com os pedidos publicados em 2. Um, em que não houve renumeração (result_f_p1xm, para fazer um merge apenas) e outro (result_f_p2xm), contendo uma coluna a mais com a nova numeração do pedido. No arquivo em que temos somente pedidos que foram renumerados, teremos que fazer 2x o merge. No primeiro merge, faremos considerando a numeração antiga, na segunda, a nova numeração, e depois verificaremos via excel. Os arquivos já preparados, serão mostrados abaixo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJo-YM3BiQik"
      },
      "source": [
        "O arquivo que faremos o merge é o outros_f_pm, também preparado no excel, em que algumas verificações de data e informações foram feitas, bem como a exclusão dos pedidos com data de depósito inferior a 1993."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvw7tggrfuQo"
      },
      "source": [
        "import pandas as pd\n",
        "outros_f_pm=pd.read_csv('outros_f_pm.csv',encoding='iso-8859-1',delimiter=';')\n",
        "result_f_p1xm=pd.read_csv('result_f_p1xm.csv',encoding='iso-8859-1',delimiter=';')\n",
        "result_f_p2xm=pd.read_csv('result_f_p2xm.csv',encoding='iso-8859-1',delimiter=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evQcz4wkfuXA"
      },
      "source": [
        "outros_f_pm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5YS6r-ifueS"
      },
      "source": [
        "result_f_p1xm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw4cy8-zfunD"
      },
      "source": [
        "result_f_p2xm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GaLkKXvLA9y"
      },
      "source": [
        "Vamos juntar os dois dataframes utilizando o método merge:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8XEWUrHK6p4"
      },
      "source": [
        "def e_desp(df):\n",
        "  df1=[]\n",
        "  c=['6.1','6.20','6.21','6.22','7.1','8.6','8.11','8.12','9.1','9.2','11.1.1','11.2','11.4','11.6','11.11','11.18','11.30','11.31']\n",
        "  for desp in c:\n",
        "    at=df.loc[df['despacho'] == desp].sort_values(by=['chave_idpedido','data_rpi'])\n",
        "    at = at.reset_index(drop=True)\n",
        "    at['chave_idpedido'].value_counts()\n",
        "    at[desp] = at.groupby('chave_idpedido')['chave_idpedido'].transform('count')\n",
        "    at=at.drop_duplicates(subset='chave_idpedido', keep=\"last\")\n",
        "    del at['despacho']\n",
        "    at=at[['chave_idpedido',desp,'data_rpi']]\n",
        "    at = at.reset_index(drop=True)\n",
        "    df1.append(at)\n",
        "\n",
        "  return df1[0], df1[1], df1[2], df1[3], df1[4], df1[5], df1[6], df1[7], df1[8], df1[9], df1[10], df1[11], df1[12], df1[13], df1[14], df1[15], df1[16], df1[17]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpXEJ5u8K60y"
      },
      "source": [
        "df_6_1, df_6_20, df_6_21, df_6_22, df_7_1, df_8_6, df_8_11, df_8_12, df_9_1, df_9_2, df_11_1_1, df_11_2,df_11_4,df_11_6,df_11_11,df_11_18,df_11_30,df_11_31=e_desp(outros_f_pm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_8MAz_UK64W"
      },
      "source": [
        "a=[df_6_1,df_6_20,df_6_21,df_6_22,df_7_1,df_8_6,df_8_11,df_8_12,df_9_1,df_9_2,df_11_1_1,df_11_2,df_11_4,df_11_6,df_11_11,df_11_18,df_11_30,df_11_31]\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3cYOl_wK67q"
      },
      "source": [
        "for i in a:\n",
        "  result_f_p1xm=pd.merge(result_f_p1xm,i,how='outer',on=['chave_idpedido'])\n",
        "  result_f_p2xm=pd.merge(result_f_p2xm,i,how='outer',on=['chave_idpedido']) # primeiro merge, a chave idpedido do dataframe result_f_p2xm está ativada na 1º coluna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD2tTYhbdzyd"
      },
      "source": [
        "result_f_p1xm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCVSVLJJeWio"
      },
      "source": [
        "result_f_p2xm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HzkybdUpD2M"
      },
      "source": [
        "result_f_p2xm = result_f_p2xm.drop(result_f_p2xm[1303:].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1Tv-CM0p6gH"
      },
      "source": [
        "Alterando a chave do result_f_p2xm para a nova numeração, pela simples alteração do nome da coluna e refazendo o merge:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5jpX2mhpD7a"
      },
      "source": [
        "result_f_p2xm.rename(columns={'chave_idpedido': 'num_anterior', 'nova_num': 'chave_idpedido'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmh7i6ospEBm"
      },
      "source": [
        "result_f_p2xm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH3ui-8RrQ8V"
      },
      "source": [
        "for i in a:\n",
        "  result_f_p2xm=pd.merge(result_f_p2xm,i,how='outer',on=['chave_idpedido']) # segundo merge, a chave idpedido do dataframe result_f_p2xm está ativada na coluna com a nova numeração"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0duhHwwrRI7"
      },
      "source": [
        "result_f_p2xm = result_f_p2xm.drop(result_f_p2xm[1303:].index)\n",
        "result_f_p2xm.rename(columns={'num_anterior':'chave_idpedido', 'chave_idpedido':'nova_num'}, inplace=True)\n",
        "result_f_p2xm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrGxSdKRG1Lw"
      },
      "source": [
        "Este dataframe completo, contendo os dados bibliográficos dos pedidos e as ações que estes pedidos sofreram ao longo do tempo não terá utilidade neste trabalho específico, mas somente para uso interno do INPI.\n",
        "Os dados utilizados serão os dados compilados dos dataframes que contém somente os dados bibliográficos e do dataframe outros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHAHJ_NLrRNY"
      },
      "source": [
        "dupl=result_f_p1xm['chave_idpedido'].value_counts().rename_axis('unique_values').to_frame('counts')\n",
        "dupl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPAO84QuUL3o"
      },
      "source": [
        "dupl=result_f_p2xm['chave_idpedido'].value_counts().rename_axis('unique_values').to_frame('counts')\n",
        "dupl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HGYnbLxQG5p"
      },
      "source": [
        "result_f_p1xm.to_csv(\"result_f_1.csv\", index=False)\n",
        "result_f_p2xm.to_csv(\"result_f_2.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpFyo2xy5nST"
      },
      "source": [
        "Terminamos a segunda etapa! Vamos à terceira etapa do trabalho."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_hN4_TSRGT3"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"result_f_1.csv\") \n",
        "files.download(\"result_f_2.csv\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MvjqydX9l27"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"outros_f.csv\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTAGjtm9_lVT"
      },
      "source": [
        "# **TERCEIRA ETAPA - Análise, exploração e representação dos dados**\n",
        "\n",
        "Neste etapa será possível encontrar padrões e tendências sobre o depósito de patentes no Brasil de distintas áreas tecnológicas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03tNDql2xvly"
      },
      "source": [
        "Houve a necessidade de reagrupar os dados no excel e padronizar ao menos 150 nomes de depositantes, para contagem correta dos depositantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27QCgGuNPjY-"
      },
      "source": [
        "Além disso, foram corrigidas algumas datas e excluídos os pedidos depositados antes de 1993. Sendo os dados estudados daqui em diante no período de 1993 a 2016. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd4RbRi4P1qd"
      },
      "source": [
        "Vamos aos gráficos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-ofAcQwDiMf"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22mcz6QvkQrd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-cGso1SOwfA"
      },
      "source": [
        "# Lendo o arquivo Dados_Final.csv\n",
        "Dados_Final=pd.read_csv('Dados_Final.csv',encoding='iso-8859-1',delimiter=';')\n",
        "Dados_Final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smTnOLCNPOal"
      },
      "source": [
        "Dados_Final['depositante'].value_counts().rename_axis('unique_values').to_frame('counts')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSiV7M5VP7T2"
      },
      "source": [
        "Total de despachos de interesse da Diretoria de Patentes, por ano no Brasil:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4gxTouhSJSH"
      },
      "source": [
        "# Lendo o arquivo despachoxano.csv\n",
        "despachos_ano=pd.read_csv('despachosxano.csv',encoding='iso-8859-1',delimiter=';')\n",
        "despachos_ano"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUBI8ncMDi1v"
      },
      "source": [
        "# substituindo os valores nan por 0 no dataframe\n",
        "despachos_ano=despachos_ano.fillna(0)\n",
        "despachos_ano"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kJjRIvUefDd"
      },
      "source": [
        "Os dados de despachos podem ver visualizados no período de 1993 a 2020 (até 08/12/2020), sendo que estas publicações demonstram, efetivamente, o que o INPI produziu até a data de publicação da RPI.\n",
        "Já no caso da publicação de pedidos de patentes, há um risco de ter pedidos PCT ainda não analisados pela área designada para tal tarefa, por isso utilizaremos os dados no período de 1993 a 2016."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LscscnjxDjLY"
      },
      "source": [
        "# altera a fonte dos eixos\n",
        "ft=12\n",
        "plt.rcParams.update({'font.size':ft})\n",
        "\n",
        "# mostra o tamanho default do gráfico\n",
        "fig_size=plt.rcParams['figure.figsize']\n",
        "fig_size\n",
        "\n",
        "# altera o tamanho do gráfico\n",
        "fig_size[0]=18\n",
        "fig_size[1]=10\n",
        "\n",
        "for ind in despachos_ano.index:\n",
        "  plt.plot(despachos_ano.iloc[ind][1::])\n",
        "plt.legend(despachos_ano['Despachos'].values)\n",
        "plt.xlabel('Ano')\n",
        "plt.ylabel('Despacho publicados')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LaYUZs7YOZi"
      },
      "source": [
        "Pode-se notar que o número total de despachos, ditos despachos de decisão (9.1 - Deferimento, 9.2 - Indeferimento, 11.2 - Arquivamento definitivo e 11.5 - Arquivamento) começaram a ter um aumento significativo a partir de 2016. O que evidencia um aumento significativo no número de decisões da Diretoria de Patentes. Uma das razões para este aumento na produtividade da DIRPA tem relação direta com o plano de ataque ao BACKLOG do INPI, bem como ao aumento significativo na quantidade de pedidos de patentes analisados pelos examinadores de patentes do Instituto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN9c1FGwgq_u"
      },
      "source": [
        "Pedidos de patentes de residentes (nacionais) e não residentes (internacionais)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th9aELsId2M5"
      },
      "source": [
        "# Lendo o arquivo despachoxano.csv\n",
        "res_nao_res_ano=pd.read_csv('res_nao_resxano.csv',encoding='iso-8859-1',delimiter=';')\n",
        "res_nao_res_ano"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGQsyPimd2a2"
      },
      "source": [
        "for ind in res_nao_res_ano.index:\n",
        "  plt.plot(res_nao_res_ano.iloc[ind][1::])\n",
        "plt.legend(res_nao_res_ano['Ano'].values)\n",
        "plt.xlabel('Ano')\n",
        "plt.ylabel('Número de pedidos de patentes publicados')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A55C4U09h0o_"
      },
      "source": [
        "Pela evolução do gráfico, é notória a diferença entre o depósito de pedidos de patentes nacional e internacional. Observa-se que entre 1993 e 1995 a diferença entre os depósitos nacionais e internacionais era bem menor quando compara-se esta diferença, por exemple, em 2013. Inúmeras explicações podem ser dadas a este fato. Fatores sócio-econômicos, investimento em ciência/inovação e tratados internacionais podem ser citados para explicar tal discrepância, mas foge do escopo do presente trabalho.\n",
        "\n",
        "Destes depositantes internacionais, quais os países com maior número de pedidos ao longo dos anos? Quais os estados brasileiros que mais depositam patentes?\n",
        "Veremos nos próximos gráficos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVzRcxb8raII"
      },
      "source": [
        "Número total de depósitos de pedidos por país por ano:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2_XDr97d2mH"
      },
      "source": [
        "# Importando bibliotecas para gráfico de barras horizontal\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuThv2fClLaI"
      },
      "source": [
        "# Lendo o arquivo despachoxano.csv\n",
        "pais_ano=pd.read_csv('paisxano.csv',encoding='iso-8859-1',delimiter=';')\n",
        "pais_ano"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nGcj8GOlLf-"
      },
      "source": [
        "# substituindo os valores nan por 0 no dataframe\n",
        "pais_ano=pais_ano.fillna(0)\n",
        "pais_ano"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yJ1HmB4Xwde"
      },
      "source": [
        "# Pegando apenas o ano de 2016\n",
        "current_Ano = 2016\n",
        "pais_ano_1 = (pais_ano[pais_ano['Ano'].eq(current_Ano)]\n",
        "       .sort_values(by='Depósitos', ascending=False).head(10))\n",
        "pais_ano_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV99CSjWlLme"
      },
      "source": [
        "#plotando no gráfico de barras horizontal\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "ax.barh(pais_ano_1['País'], pais_ano_1['Depósitos'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFebjBPIl7-a"
      },
      "source": [
        "# Vamos adicionar cores de acordo com o continente de cada país\n",
        "colors = dict(zip(\n",
        "    ['Oceania', 'Europe', 'Asia', 'Latin America', 'North America'],\n",
        "    ['#adb0ff', '#aafbff', '#90d595', '#e48381', '#f7bb5f']\n",
        "))\n",
        "group_lk = pais_ano.set_index('País')['Continente'].to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glGQ-SwEqZrJ"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "pais_ano_1 = pais_ano_1[::-1]   # flip values from top to bottom\n",
        "# pass colors values to `color=`\n",
        "ax.barh(pais_ano_1['País'], pais_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in pais_ano_1['País']])\n",
        "# iterate over the values to plot labels and values\n",
        "for i, (Depósitos, País) in enumerate(zip(pais_ano_1['Depósitos'], pais_ano_1['País'])):\n",
        "    ax.text(Depósitos, i,     País,            ha='right')  # País: name\n",
        "    ax.text(Depósitos, i-.25, group_lk[País],  ha='right')  # Asia: Continente\n",
        "    ax.text(Depósitos, i,     Depósitos,           ha='left')   # Depósitos\n",
        "# Add year right middle portion of canvas\n",
        "ax.text(1, 0.4, current_Ano, transform=ax.transAxes, size=46, ha='right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi8yf1nIJAwd"
      },
      "source": [
        "# Melhorando a apresentação do gráfico\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "def draw_barchart(ano):\n",
        "    pais_ano_1 = pais_ano[pais_ano['Ano'].eq(ano)].sort_values(by='Depósitos', ascending=True).tail(10)\n",
        "    ax.clear()\n",
        "    ax.barh(pais_ano_1['País'], pais_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in pais_ano_1['País']])\n",
        "    dx = pais_ano_1['Depósitos'].max() / 200\n",
        "    for i, (Depósitos, País) in enumerate(zip(pais_ano_1['Depósitos'], pais_ano_1['País'])):\n",
        "        ax.text(Depósitos-dx, i,     País,           size=14, weight=600, ha='right', va='bottom')\n",
        "        ax.text(Depósitos-dx, i-.25, group_lk[País], size=10, color='#444444', ha='right', va='baseline')\n",
        "        ax.text(Depósitos+dx, i,     f'{Depósitos:,.0f}',  size=14, ha='left',  va='center')\n",
        "    # ... polished styles\n",
        "    ax.text(1, 0.4, ano, transform=ax.transAxes, color='#777777', size=46, ha='right', weight=800)\n",
        "    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.tick_params(axis='x', colors='#777777', labelsize=12)\n",
        "    ax.set_yticks([])\n",
        "    ax.margins(0, 0.01)\n",
        "    ax.grid(which='major', axis='x', linestyle='-')\n",
        "    ax.set_axisbelow(True)\n",
        "    ax.text(0, 1.12, 'Países com maior número de depósitos de pedidos de patente no Brasil',\n",
        "            transform=ax.transAxes, size=24, weight=600, ha='left')\n",
        "    plt.box(False)\n",
        "    \n",
        "draw_barchart(2016)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZkIDW_2JGZf"
      },
      "source": [
        "# Finalmente, utilizando o recurso de animação do matplotlib\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "fig, ax = plt.subplots(figsize=(18, 10))\n",
        "animator = animation.FuncAnimation(fig, draw_barchart, frames=range(1993, 2017))\n",
        "HTML(animator.to_jshtml()) \n",
        "# or use animator.to_html5_video() or animator.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4OPvGyhAkII"
      },
      "source": [
        "animator.save('pais_ano.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUwb1XoMBZQg"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('pais_ano.mp4') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze8KQekTPgZ7"
      },
      "source": [
        "Pela visualização do vídeo 1, podemos observar que no período de 1993 a 1997 o Brasil era o que mantinha o maior número de depósitos de pedidos de patente em seu território. Em 1998 e 1999 os Estados Unidos assumiram a liderança e, de 1999 a 2005, o Brasil voltou a ser o primeiro em número de depósitos. Após 2005, os Estados Unidos seguiram como os maiores depositantes em território brasileiro, se afastando cada vez dos depositantes nacionais, e de outros países, até 2016. Como pode ser visto na figura 3. Também é notório que o continente europeu é maioria entre os 10 maiores depositantes, independente do ano. O Japão seguia isolado como representante asiático até o ano de 2012, sendo que a partir de 2013 a China entra para seleto grupo dos top 10.\n",
        "\n",
        "Outra pergunta interessante que podemos responder com os dados compilados é: Qual empresa possuir maior depósito de pedidos de patentes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW2-7FUHogTQ"
      },
      "source": [
        "Depósitos de pedidos de patentes de empresas por ano:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lYuhPMmJGls"
      },
      "source": [
        "# Lendo o arquivo despachoxano.csv\n",
        "dep_ano=pd.read_csv('depositantexano.csv',encoding='iso-8859-1',delimiter=';')\n",
        "\n",
        "# substituindo os valores nan por 0 no dataframe\n",
        "dep_ano=dep_ano.fillna(0)\n",
        "dep_ano"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTbv_wMSqfLv"
      },
      "source": [
        "# Verificando quais os países contém os dados\n",
        "pais_un=dep_ano['País'].value_counts().rename_axis('unique_values').to_frame('counts')\n",
        "pais_un"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFUgCt2u76kI"
      },
      "source": [
        "# Pegando apenas o ano de 2016\n",
        "current_Ano = 2016\n",
        "dep_ano_1 = (dep_ano[dep_ano['Ano'].eq(current_Ano)]\n",
        "       .sort_values(by='Depósitos', ascending=False).head(10))\n",
        "dep_ano_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI3g-l8rqZRg"
      },
      "source": [
        "# Vamos adicionar cores de acordo com cada país\n",
        "colors = dict(zip(\n",
        "    ['United States', 'Deutschland', 'Netherlands', 'Switzerland', 'France','Korea','Japan','Sweden'],\n",
        "    ['#D84E4E', '#aafbff', '#90d595', '#e48381', '#f7bb5f','#1f77b4','#e377c2','#9467bd']\n",
        "))\n",
        "group_lk = dep_ano.set_index('Depositante')['País'].to_dict()\n",
        "group_lk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wq-ztL68v42"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "dep_ano_1 = dep_ano_1[::-1]   # flip values from top to bottom\n",
        "# pass colors values to `color=`\n",
        "ax.barh(dep_ano_1['Depositante'], dep_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in dep_ano_1['Depositante']])\n",
        "# iterate over the values to plot labels and values\n",
        "for i, (Depósitos, Depositante) in enumerate(zip(dep_ano_1['Depósitos'], dep_ano_1['Depositante'])):\n",
        "    #ax.text(Depósitos, i,     Depositante,            ha='right')  \n",
        "    ax.text(Depósitos, i-.25, group_lk[Depositante],  ha='right')  \n",
        "    ax.text(Depósitos, i,     Depósitos,           ha='left')   \n",
        "# Add year right middle portion of canvas\n",
        "ax.text(1, 0.4, current_Ano, transform=ax.transAxes, size=46, ha='right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLLSU6UX8wE4"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "def draw_barchart(ano):\n",
        "    dep_ano_1 = dep_ano[dep_ano['Ano'].eq(ano)].sort_values(by='Depósitos', ascending=True).tail(10)\n",
        "    ax.clear()\n",
        "    ax.barh(dep_ano_1['Depositante'], dep_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in dep_ano_1['Depositante']])\n",
        "    dx = dep_ano_1['Depósitos'].max() / 200\n",
        "    for i, (Depósitos, Depositante) in enumerate(zip(dep_ano_1['Depósitos'], dep_ano_1['Depositante'])):\n",
        "        ax.text(Depósitos-dx, i,     Depositante,           size=14, weight=600, ha='right', va='bottom')\n",
        "        ax.text(Depósitos-dx, i-.25, group_lk[Depositante], size=12, ha='right', va='baseline')\n",
        "        ax.text(Depósitos+dx, i,     f'{Depósitos:,.0f}',  size=14, ha='left',  va='center')\n",
        "    # ... polished styles\n",
        "    ax.text(1, 0.4, ano, transform=ax.transAxes, color='#777777', size=46, ha='right', weight=800)\n",
        "    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.tick_params(axis='x', colors='#777777', labelsize=12)\n",
        "    ax.set_yticks([])\n",
        "    ax.margins(0, 0.01)\n",
        "    ax.grid(which='major', axis='x', linestyle='-')\n",
        "    ax.set_axisbelow(True)\n",
        "    ax.text(0, 1.12, 'Empresas com maior número de depósitos de pedidos de patente no Brasil',\n",
        "            transform=ax.transAxes, size=24, weight=600, ha='left')\n",
        "    plt.box(False)\n",
        "    \n",
        "draw_barchart(2016)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N3jJD4z8wK_"
      },
      "source": [
        "# Finalmente, utilizando o recurso de animação do matplotlib\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "animator = animation.FuncAnimation(fig, draw_barchart, frames=range(1993, 2017))\n",
        "HTML(animator.to_jshtml()) \n",
        "# or use animator.to_html5_video() or animator.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5sDYuubLgRU"
      },
      "source": [
        "animator.save('depositante_ano.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjWAzxInLg69"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('depositante_ano.mp4') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlIXL8c7ZlSo"
      },
      "source": [
        "A empresa com maior número de pedidos de patentes no Brasil, no período de 1993 a 2000 foi a Procter & Gamble, empresa americana de bens consumo que abrange diversos produtoas, dentre os quais se destacam os de higiene pessoal. Em 2001 foi a vez da Bosch dominar o depósito de pedidos de patentes no Brasil, empresa notadamente conhecida por soluções automotivas e máquinas ferramentas. Nos anos de 2002, 2003, 2006 a 2009 e 2014 a 2016, a Qualcomm dominou o primeiro lugar no depósito de pedidos de patentes, isto é, nove anos de domínio de inovação no país. A Qualcomm é uma empresa destacadamente conhecida no ramo da telecomunicação. Em 2004 e 2005 o destaque foi para as companhias Basf e Microsoft. A Basf, empresa bastente conhecida na área química, atua em diversas áreas, fornecendo soluções diversas para inúmeras áreas. A Microsoft, dispensa comentários. Já no período de 2010 a 2013 a Philips emplacou o primeiro lugar no depósito de pedidos de patentes. Empresa conhecida por produtos eletrônicos voltados para a área de higiene pessoal, setor automotivo e acessórios diversos.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTVcYb29iqFU"
      },
      "source": [
        "Com os dados das RPI's, foi possível saber, quantitativamente, quais os países com maior número de depósito de pedidos de patentes e quais as empresas dominam o cenário geral de inovação no Brasil. Podemos perguntar também, quais os estados brasileiros possuem o maior número de depósito de pediddos de patentes? E quais as empresas nacionais são destaques em inovação?\n",
        "Veremos a seguir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzZffQQjKhJx"
      },
      "source": [
        "Depósitos de pedidos de patentes por estado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hfvNbKXArre"
      },
      "source": [
        "# Lendo o arquivo despachoxano.csv\n",
        "est_ano=pd.read_csv('estadoxano.csv',encoding='iso-8859-1',delimiter=';')\n",
        "\n",
        "# substituindo os valores nan por 0 no dataframe\n",
        "est_ano=est_ano.fillna(0)\n",
        "est_ano"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmXcFqPQ2ZA6"
      },
      "source": [
        "# Pegando apenas o ano de 2016\n",
        "current_Ano = 2016\n",
        "est_ano_1 = (est_ano[est_ano['Ano'].eq(current_Ano)]\n",
        "       .sort_values(by='Depósitos', ascending=False).head(10))\n",
        "est_ano_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg8SeM-G1BVR"
      },
      "source": [
        "# Vamos adicionar cores de acordo com cada país\n",
        "colors = dict(zip(\n",
        "    ['Sudeste', 'Sul', 'Nordeste', 'Norte', 'Centro-Oeste'],\n",
        "    ['#D84E4E', '#aafbff', '#90d595', '#e48381', '#f7bb5f']\n",
        "))\n",
        "group_lk = est_ano.set_index('Estado')['Região'].to_dict()\n",
        "group_lk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0jR3sGL1Yka"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "est_ano_1 = est_ano_1[::-1]   # flip values from top to bottom\n",
        "# pass colors values to `color=`\n",
        "ax.barh(est_ano_1['Estado'], est_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in est_ano_1['Estado']])\n",
        "# iterate over the values to plot labels and values\n",
        "for i, (Depósitos, País) in enumerate(zip(est_ano_1['Depósitos'], est_ano_1['Estado'])):\n",
        "    ax.text(Depósitos, i,     País,            ha='right')  # País: name\n",
        "    ax.text(Depósitos, i-.25, group_lk[País],  ha='right')  # Asia: Continente\n",
        "    ax.text(Depósitos, i,     Depósitos,           ha='left')   # Depósitos\n",
        "# Add year right middle portion of canvas\n",
        "ax.text(1, 0.4, current_Ano, transform=ax.transAxes, size=46, ha='right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDEgGZCN3ZWC"
      },
      "source": [
        "# Melhorando a apresentação do gráfico\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "def draw_barchart(ano):\n",
        "    est_ano_1 = est_ano[est_ano['Ano'].eq(ano)].sort_values(by='Depósitos', ascending=True).tail(10)\n",
        "    ax.clear()\n",
        "    ax.barh(est_ano_1['Estado'], est_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in est_ano_1['Estado']])\n",
        "    dx = est_ano_1['Depósitos'].max() / 200\n",
        "    for i, (Depósitos, País) in enumerate(zip(est_ano_1['Depósitos'], est_ano_1['Estado'])):\n",
        "        ax.text(Depósitos-dx, i,     País,           size=14, weight=600, ha='right', va='bottom')\n",
        "        ax.text(Depósitos-dx, i-.25, group_lk[País], size=10, color='#444444', ha='right', va='baseline')\n",
        "        ax.text(Depósitos+dx, i,     f'{Depósitos:,.0f}',  size=14, ha='left',  va='center')\n",
        "    # ... polished styles\n",
        "    ax.text(1, 0.4, ano, transform=ax.transAxes, color='#777777', size=46, ha='right', weight=800)\n",
        "    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.tick_params(axis='x', colors='#777777', labelsize=12)\n",
        "    ax.set_yticks([])\n",
        "    ax.margins(0, 0.01)\n",
        "    ax.grid(which='major', axis='x', linestyle='-')\n",
        "    ax.set_axisbelow(True)\n",
        "    ax.text(0, 1.12, 'Estado com maior número de depósitos de pedidos de patente no Brasil',\n",
        "            transform=ax.transAxes, size=24, weight=600, ha='left')\n",
        "    plt.box(False)\n",
        "    \n",
        "draw_barchart(2016)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTJ1kQjs4V3s"
      },
      "source": [
        "# Finalmente, utilizando o recurso de animação do matplotlib\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "animator = animation.FuncAnimation(fig, draw_barchart, frames=range(1993, 2017))\n",
        "HTML(animator.to_jshtml()) \n",
        "# or use animator.to_html5_video() or animator.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTkiKG5Uvzpz"
      },
      "source": [
        "animator.save('estado_ano.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CSN1gzu4-Vg"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('estado_ano.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDoileCL6_xi"
      },
      "source": [
        "É notório a hegemonia das regiões sudeste e sul no cenário de inovação brasileiro. Destaque para os estados de São Paulo (desde 1993 está em primeiro lugar nos top 10), Rio de Janeiro, Rio Grande do Sul, Minas Gerais, Paraná e Santa Catarina.\n",
        "\n",
        "Estas informações são consistentes, pois como citado em estudos anteriores, há uma forte correlação entre o PIB e o número de depósitos de pedidos de patentes. Estes estados que ocupam os 6 primeiros lugares desde 1993 são os estados com o maior PIB do Brasil, conforme levantamento do IBGE (https://www.ibge.gov.br/explica/pib.php).\n",
        "\n",
        "São Paulo é o primeiro por questões óbvias, pois é a capital econômica do país, sendo o estado com maior número de empresas e concentrador da maior parte da pesquisa científica do país."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnXHMdGAn5wT"
      },
      "source": [
        "Maiores depositantes de pedidos de patentes nacionais:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T4ouiOYYZGG"
      },
      "source": [
        "import pandas as pd\n",
        "# Lendo o arquivo despachoxano.csv\n",
        "dep_res_ano=pd.read_csv('depositante_residentexano.csv',encoding='iso-8859-1',delimiter=';')\n",
        "\n",
        "# substituindo os valores nan por 0 no dataframe\n",
        "dep_res_ano=dep_res_ano.fillna(0)\n",
        "dep_res_ano"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNZ30ibeBnYX"
      },
      "source": [
        "# Pegando apenas o ano de 2016\n",
        "current_Ano = 2016\n",
        "dep_res_ano_1 = (dep_res_ano[dep_res_ano['Ano'].eq(current_Ano)]\n",
        "       .sort_values(by='Depósitos', ascending=False).head(10))\n",
        "dep_res_ano_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRsVSqKjBneR"
      },
      "source": [
        "# Vamos adicionar cores de acordo com cada grupo (como são 2400 linhas, dividimos em 5 partes - 240 primeiros para o grupo A, após classificar por ordem alfabética, B para os próximos 240 e assim sucessivamente)\n",
        "colors = dict(zip(\n",
        "    ['A', 'B', 'C', 'D', 'E'],\n",
        "    ['#D84E4E', '#aafbff', '#90d595', '#e48381', '#f7bb5f']\n",
        "))\n",
        "group_lk = dep_res_ano.set_index('Depositante')['Grupo'].to_dict()\n",
        "group_lk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qol0dajBnls"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "dep_res_ano_1= dep_res_ano_1[::-1]   # flip values from top to bottom\n",
        "# pass colors values to `color=`\n",
        "ax.barh(dep_res_ano_1['Depositante'], dep_res_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in dep_res_ano_1['Depositante']])\n",
        "# iterate over the values to plot labels and values\n",
        "for i, (Depósitos, Depositante) in enumerate(zip(dep_res_ano_1['Depósitos'], dep_res_ano_1['Depositante'])):\n",
        "    #ax.text(Depósitos, i,     Depositante,            ha='right')  \n",
        "    ax.text(Depósitos, i-.25, group_lk[Depositante],  ha='right')  \n",
        "    ax.text(Depósitos, i,     Depósitos,           ha='left')   \n",
        "# Add year right middle portion of canvas\n",
        "ax.text(1, 0.4, current_Ano, transform=ax.transAxes, size=46, ha='right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB5QmG_UBnwu"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "def draw_barchart(ano):\n",
        "    dep_res_ano_1 = dep_res_ano[dep_res_ano['Ano'].eq(ano)].sort_values(by='Depósitos', ascending=True).tail(10)\n",
        "    ax.clear()\n",
        "    ax.barh(dep_res_ano_1['Depositante'], dep_res_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in dep_res_ano_1['Depositante']])\n",
        "    dx = dep_res_ano_1['Depósitos'].max() / 200\n",
        "    for i, (Depósitos, Depositante) in enumerate(zip(dep_res_ano_1['Depósitos'], dep_res_ano_1['Depositante'])):\n",
        "        ax.text(Depósitos-dx, i,     Depositante,           size=14, weight=600, ha='right', va='bottom')\n",
        "        ax.text(Depósitos-dx, i-.25, group_lk[Depositante], size=12, ha='right', va='baseline')\n",
        "        ax.text(Depósitos+dx, i,     f'{Depósitos:,.0f}',  size=14, ha='left',  va='center')\n",
        "    # ... polished styles\n",
        "    ax.text(1, 0.4, ano, transform=ax.transAxes, color='#777777', size=46, ha='right', weight=800)\n",
        "    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.tick_params(axis='x', colors='#777777', labelsize=12)\n",
        "    ax.set_yticks([])\n",
        "    ax.margins(0, 0.01)\n",
        "    ax.grid(which='major', axis='x', linestyle='-')\n",
        "    ax.set_axisbelow(True)\n",
        "    ax.text(0, 1.12, 'Empresas residentes no BR com maior n.º de pedidos de patente no BR',\n",
        "            transform=ax.transAxes, size=24, weight=600, ha='left')\n",
        "    plt.box(False)\n",
        "    \n",
        "draw_barchart(2016)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB8zhDTbzc5k"
      },
      "source": [
        "# Finalmente, utilizando o recurso de animação do matplotlib\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "animator = animation.FuncAnimation(fig, draw_barchart, frames=range(1993, 2017))\n",
        "HTML(animator.to_jshtml()) \n",
        "# or use animator.to_html5_video() or animator.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgPbuo544OEG"
      },
      "source": [
        "As empresas residentes que mostram maior número de pedidos de patentes no Brasil ao longo dos anos são notadamente a Petrobrás, CSN, Cia Vale do Rio Doce, Usiminas e Whirlpool. Além destas empresas, as universidades públicas também estão entres os 10 ao longo dos anos, cito: Unicamp, UFMG, USP, UFRJ, UFPR, UFRGS dentre outras federais. Interesse notar que em 2016, dos 10 maiores depositantes, 9 são universidades!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-sBDYt8PQY6"
      },
      "source": [
        "Sabemos quais empresas e países possuem o maior número de pedidos de patentes no Brasil. Agora, quais tecnologias são de maior interesse dos 2 países com maior número de depositos no INPI? Isto é, quais são as tecnologias de maior interesse destes países?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqgfg7yESi5V"
      },
      "source": [
        "animator.save('residente_ano.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0prXnPDSkY9"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('residente_ano.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq0OuM0GPUEN"
      },
      "source": [
        "Evolução das tecnologias, dos Estados Unidos,  com maior número de depósitos de pedidos de patente no Brasil:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyEZSQcQzdTF"
      },
      "source": [
        "import pandas as pd\n",
        "# Lendo o arquivo despachoxano.csv\n",
        "ompi_US_ano=pd.read_csv('ompi_USxano.csv',encoding='iso-8859-1',delimiter=';')\n",
        "\n",
        "# substituindo os valores nan por 0 no dataframe\n",
        "ompi_US_ano=ompi_US_ano.fillna(0)\n",
        "ompi_US_ano"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG8Mmxkfzdjr"
      },
      "source": [
        "# Pegando apenas o ano de 2016\n",
        "current_Ano = 2016\n",
        "ompi_US_ano_1 = (ompi_US_ano[ompi_US_ano['Ano'].eq(current_Ano)]\n",
        "       .sort_values(by='Depósitos', ascending=False).head(10))\n",
        "ompi_US_ano_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee6i5kgSzds4"
      },
      "source": [
        "# Vamos adicionar cores de acordo com a área tecnologica (Química, Instrumentos, Engenharia mecânica, Engenharia elétrica, Outras áreas - divisão esta utilizada pela WIPO)\n",
        "colors = dict(zip(\n",
        "    ['Química', 'Instrumentos', 'Engenharia mecânica', 'Engenharia elétrica', 'Outras áreas'],\n",
        "    ['#D84E4E', '#aafbff', '#90d595', '#e48381', '#f7bb5f']\n",
        "))\n",
        "group_lk = ompi_US_ano.set_index('Campo_Tec')['Area_Tec'].to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRoxz-_5QwcL"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "ompi_US_ano_1= ompi_US_ano_1[::-1]   # flip values from top to bottom\n",
        "# pass colors values to `color=`\n",
        "ax.barh(ompi_US_ano_1['Campo_Tec'], ompi_US_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in ompi_US_ano_1['Campo_Tec']])\n",
        "# iterate over the values to plot labels and values\n",
        "for i, (Depósitos, Depositante) in enumerate(zip(ompi_US_ano_1['Depósitos'], ompi_US_ano_1['Campo_Tec'])):\n",
        "    #ax.text(Depósitos, i,     Depositante,            ha='right')  \n",
        "    ax.text(Depósitos, i-.25, group_lk[Depositante],  ha='right')  \n",
        "    ax.text(Depósitos, i,     Depósitos,           ha='left')   \n",
        "# Add year right middle portion of canvas\n",
        "ax.text(1, 0.4, current_Ano, transform=ax.transAxes, size=46, ha='right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf4gAr0EQwhE"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "def draw_barchart(ano):\n",
        "    ompi_US_ano_1 = ompi_US_ano[ompi_US_ano['Ano'].eq(ano)].sort_values(by='Depósitos', ascending=True).tail(10)\n",
        "    ax.clear()\n",
        "    ax.barh(ompi_US_ano_1['Campo_Tec'], ompi_US_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in ompi_US_ano_1['Campo_Tec']])\n",
        "    dx = ompi_US_ano_1['Depósitos'].max() / 200\n",
        "    for i, (Depósitos, Depositante) in enumerate(zip(ompi_US_ano_1['Depósitos'], ompi_US_ano_1['Campo_Tec'])):\n",
        "        ax.text(Depósitos-dx, i,     Depositante,           size=14, weight=600, ha='right', va='bottom')\n",
        "        ax.text(Depósitos-dx, i-.25, group_lk[Depositante], size=12, ha='right', va='baseline')\n",
        "        ax.text(Depósitos+dx, i,     f'{Depósitos:,.0f}',  size=14, ha='left',  va='center')\n",
        "    # ... polished styles\n",
        "    ax.text(1, 0.4, ano, transform=ax.transAxes, color='#777777', size=46, ha='right', weight=800)\n",
        "    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.tick_params(axis='x', colors='#777777', labelsize=12)\n",
        "    ax.set_yticks([])\n",
        "    ax.margins(0, 0.01)\n",
        "    ax.grid(which='major', axis='x', linestyle='-')\n",
        "    ax.set_axisbelow(True)\n",
        "    ax.text(0, 1.12, 'Tecnologias, de residentes dos US, com maior núm. de pedidos no INPI',\n",
        "            transform=ax.transAxes, size=24, weight=600, ha='left')\n",
        "    plt.box(False)\n",
        "    \n",
        "draw_barchart(2016)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74jaXOLGQwlG"
      },
      "source": [
        "# Utilizando o recurso de animação do matplotlib\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "animator = animation.FuncAnimation(fig, draw_barchart, frames=range(1993, 2017))\n",
        "HTML(animator.to_jshtml()) \n",
        "# or use animator.to_html5_video() or animator.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pem-sV77WRXZ"
      },
      "source": [
        "animator.save('ompi_US_ano.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovO19TL8WTBF"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('ompi_US_ano.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb-BtVHfQ8aA"
      },
      "source": [
        "Observa-se que na década de 1990 até 2010, a área tecnológica da química ocupou os três primeiros lugares, seguida da área de instrumentos, engenharia mecânica e engenharia elétrica, tendo a última destaque para os campos tecnológicos das telecomunicações e computação. A partir de 2011 as áreas tecnológicas com maior destaque foram: Instrumentos, Engenharia civil e Engenharia elétrica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pyU0CClQwpL"
      },
      "source": [
        "import pandas as pd\n",
        "# Lendo o arquivo despachoxano.csv\n",
        "ompi_BR_ano=pd.read_csv('ompi_BRxano.csv',encoding='iso-8859-1',delimiter=';')\n",
        "\n",
        "# substituindo os valores nan por 0 no dataframe\n",
        "ompi_BR_ano=ompi_BR_ano.fillna(0)\n",
        "ompi_BR_ano"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHCo-rXAQwtN"
      },
      "source": [
        "# Pegando apenas o ano de 2016\n",
        "current_Ano = 2016\n",
        "ompi_BR_ano_1 = (ompi_BR_ano[ompi_BR_ano['Ano'].eq(current_Ano)]\n",
        "       .sort_values(by='Depósitos', ascending=False).head(10))\n",
        "ompi_BR_ano_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRxsJotfQwxR"
      },
      "source": [
        "# Vamos adicionar cores de acordo com a área tecnologica (Química, Instrumentos, Engenharia mecânica, Engenharia elétrica, Outras áreas - divisão esta utilizada pela WIPO)\n",
        "colors = dict(zip(\n",
        "    ['Química', 'Instrumentos', 'Engenharia mecânica', 'Engenharia elétrica', 'Outras áreas'],\n",
        "    ['#D84E4E', '#aafbff', '#90d595', '#e48381', '#f7bb5f']\n",
        "))\n",
        "group_lk = ompi_BR_ano.set_index('Campo_Tec')['Area_Tec'].to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mz2K_EpRm_W"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "ompi_BR_ano_1= ompi_BR_ano_1[::-1]   # flip values from top to bottom\n",
        "# pass colors values to `color=`\n",
        "ax.barh(ompi_BR_ano_1['Campo_Tec'], ompi_BR_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in ompi_BR_ano_1['Campo_Tec']])\n",
        "# iterate over the values to plot labels and values\n",
        "for i, (Depósitos, Depositante) in enumerate(zip(ompi_BR_ano_1['Depósitos'], ompi_BR_ano_1['Campo_Tec'])):\n",
        "    #ax.text(Depósitos, i,     Depositante,            ha='right')  \n",
        "    ax.text(Depósitos, i-.25, group_lk[Depositante],  ha='right')  \n",
        "    ax.text(Depósitos, i,     Depósitos,           ha='left')   \n",
        "# Add year right middle portion of canvas\n",
        "ax.text(1, 0.4, current_Ano, transform=ax.transAxes, size=46, ha='right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-J_6tRQRnKz"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "def draw_barchart(ano):\n",
        "    ompi_BR_ano_1 = ompi_BR_ano[ompi_BR_ano['Ano'].eq(ano)].sort_values(by='Depósitos', ascending=True).tail(10)\n",
        "    ax.clear()\n",
        "    ax.barh(ompi_BR_ano_1['Campo_Tec'], ompi_BR_ano_1['Depósitos'], color=[colors[group_lk[x]] for x in ompi_BR_ano_1['Campo_Tec']])\n",
        "    dx = ompi_BR_ano_1['Depósitos'].max() / 200\n",
        "    for i, (Depósitos, Depositante) in enumerate(zip(ompi_BR_ano_1['Depósitos'], ompi_BR_ano_1['Campo_Tec'])):\n",
        "        ax.text(Depósitos-dx, i,     Depositante,           size=14, weight=600, ha='right', va='bottom')\n",
        "        ax.text(Depósitos-dx, i-.25, group_lk[Depositante], size=12, ha='right', va='baseline')\n",
        "        ax.text(Depósitos+dx, i,     f'{Depósitos:,.0f}',  size=14, ha='left',  va='center')\n",
        "    # ... polished styles\n",
        "    ax.text(1, 0.4, ano, transform=ax.transAxes, color='#777777', size=46, ha='right', weight=800)\n",
        "    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.tick_params(axis='x', colors='#777777', labelsize=12)\n",
        "    ax.set_yticks([])\n",
        "    ax.margins(0, 0.01)\n",
        "    ax.grid(which='major', axis='x', linestyle='-')\n",
        "    ax.set_axisbelow(True)\n",
        "    ax.text(0, 1.12, 'Tecnologias de residentes no BR, com maior núm. de pedidos no INPI',\n",
        "            transform=ax.transAxes, size=24, weight=600, ha='left')\n",
        "    plt.box(False)\n",
        "    \n",
        "draw_barchart(2016)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8_XbAlSRnP1"
      },
      "source": [
        "# Utilizando o recurso de animação do matplotlib\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "animator = animation.FuncAnimation(fig, draw_barchart, frames=range(1993, 2017))\n",
        "HTML(animator.to_jshtml()) \n",
        "# or use animator.to_html5_video() or animator.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkobyLYVKdz1"
      },
      "source": [
        "animator.save('ompi_BR_ano.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKQ_8K0TKfrC"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('ompi_BR_ano.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdHsMWmBBIfV"
      },
      "source": [
        "# **QUARTA ETAPA - Previsão**\n",
        "\n",
        "Nesta etapa faremos a modelagem com redes neurais para prever o número de depósito de pedidos de patentes, com base no nosso histórico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQi2KKgwS0Hf"
      },
      "source": [
        "Neste última etapa, vamos dividir a modelagem em 4 partes:\n",
        "\n",
        "\n",
        "1.   Pre-processamento de dados\n",
        "2.   Construção da RNN\n",
        "3.   Fazer as previsões e analisar os resultados\n",
        "4.   Métricas de avaliação\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG-MYw68S5EW"
      },
      "source": [
        "# Parte 1 - Pre-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCtZVR-0Bh70"
      },
      "source": [
        "# Importando bibliotecas\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Conv1D, Dropout\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CDBZPRQSt8C"
      },
      "source": [
        "# Lendo os dados\n",
        "dataframe=pandas.read_csv('pub_mes.csv',usecols=[1], skipfooter=3,engine='python',encoding='iso-8859-1',delimiter=';')\n",
        "dataframe.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA-FpbuaSuGm"
      },
      "source": [
        "dataframe.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq9mBrAWT0x8"
      },
      "source": [
        "# Tamanho do data_set\n",
        "len(dataframe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0zSiBmG5a-W"
      },
      "source": [
        "Aqui tratamos os dados que vamos usar. Primeiro ajustamos a escala dos dados para ficarem entre 0 e 1. A seguir, dividimos os dados entre treino (67% primeiros meses) e testes (33% dos meses finais da série)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWe91TSYUWeR"
      },
      "source": [
        "#Converte a coluna do dataframe pandas em um vetor numpy\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "look_back = 12\n",
        "\n",
        "# Divite os dados de treino (2/3) e teste (1/3)\n",
        "# Note que a divisão não é aleatória, mas sim sequencial\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size-look_back-1:len(dataset),:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRM9xU-iVJj4"
      },
      "source": [
        "Aqui criamos nossos pares de dados $X$ e $Y$, onde $Y_{t} = X_{t-1}$ (para look_bak=1). Uma outra forma de pensar no valor de $Y$ para um dado $X$ é que ele é o próximo $X$ na série temporal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpfUz3Mv5nhV"
      },
      "source": [
        "# Recebe uma série e converte em uma matriz com séries deslocadas.\n",
        "def create_dataset(dataset, look_back=1, std=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back):\n",
        "        a = dataset[i:(i+look_back), 0]-dataset[i, 0]\n",
        "        a /= std\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0]-dataset[i + look_back-1, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "std = train[:, 0].std()\n",
        "trainX, trainY = create_dataset(train, look_back, std)\n",
        "testX, testY = create_dataset(test, look_back, std)\n",
        "# shape is [samples, time steps, features]\n",
        "\n",
        "trainX = trainX.reshape(-1, look_back, 1)\n",
        "testX = testX.reshape(-1, look_back, 1)\n",
        "trainY = trainY / 30\n",
        "testY = testY / 30\n",
        "\n",
        "trainX.shape, testX.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUpUSrC8W4NL"
      },
      "source": [
        "# Parte 2 - Construção da RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiy6CuCKWED_"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(20, input_shape=(look_back, 1), return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-DodnfaWEOB"
      },
      "source": [
        "# Treinamento\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(patience=10, factor=0.5, verbose=True),\n",
        "    ModelCheckpoint('best.model.h5', save_best_only=True),\n",
        "    EarlyStopping(patience=25, verbose=True)\n",
        "]\n",
        "\n",
        "history = model.fit(trainX, trainY, epochs=5000, batch_size=24, validation_data=(testX, testY),\n",
        "                    verbose=0, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gPmSzylWESO"
      },
      "source": [
        "df_history = pandas.DataFrame(history.history)\n",
        "ax = df_history[['val_loss', 'loss']].plot(figsize=(10, 5))\n",
        "df_history['lr'].plot(ax=ax.twinx(), color='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmSiupazX0Re"
      },
      "source": [
        "## Parte 3 - Previsões e análise dos resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuMw-szJ6UYn"
      },
      "source": [
        "# Realiza as previsões. Notar que a utilidade de prever trainX é nenhuma. Serve apenas para exibir no gráfico.\n",
        "\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0ctD80p6mMQ"
      },
      "source": [
        "Imprime o gráfico da previsão (em vermelho)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMRhwk0TYDbj"
      },
      "source": [
        "# shift train predictions for plotting\n",
        "trainPredictPlot = (trainPredict.ravel() * 30) + dataset[look_back:len(trainPredict)+look_back, 0]\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = (testPredict.ravel() * 30) + dataset[len(trainPredict)+(look_back)-1:len(dataset), 0]\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.plot(dataset)\n",
        "plt.plot(look_back+numpy.arange(len(trainPredictPlot)), trainPredictPlot)\n",
        "plt.plot(look_back+numpy.arange(len(testPredictPlot))+len(trainPredictPlot)-1, testPredictPlot)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSacsPSXZyAd"
      },
      "source": [
        "## Parte 4 - Métricas de avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1A61rPZBiHF"
      },
      "source": [
        "# Calcula os erros de previsão\n",
        "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(testY, testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}